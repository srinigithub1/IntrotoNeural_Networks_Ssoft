{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ad7ca5",
   "metadata": {},
   "source": [
    "## NEURALNETWORKSANDDEEPLEARNING/1 MODELPERFORMANCEANDFIT/NEURALNETWORKSANDDEEPLEARNING MODELPERFORMANCEANDFIT 2 EXERCISE ANSWERS ##\n",
    "#### Exercise ####\n",
    "#### Please refer to module 1 of NeuralNetworksAndDeepLearning - ModelPerformanceAndFit for tasks 1-7\n",
    "#### Task 1 \n",
    "##### Load the libraries that are used in this module.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abb2e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper packages.\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt                     \n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "# Scikit-learn packages.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "# TensorFlow and supporting packages.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4547cfb0",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Set the working directory to the data directory.\n",
    "##### Print the working directory.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e39bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/elliotstern/Library/CloudStorage/OneDrive-Personal/Data Society/intro neural nets\n",
      "/Users/elliotstern/Library/CloudStorage/OneDrive-Personal/Data Society/intro neural nets/data\n"
     ]
    }
   ],
   "source": [
    "# Set 'main_dir' to location of the project folder\n",
    "from pathlib import Path \n",
    "home_dir = Path(\".\").resolve()\n",
    "main_dir = home_dir.parent.parent\n",
    "print(main_dir)\n",
    "data_dir = str(main_dir) + \"/data\"\n",
    "print(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d373a902",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Load the dataset `bank_marketing.csv` and save it to `bank_marketing`.\n",
    "##### Print the first few rows of `bank_marketing`.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb65f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  previous     poutcome  emp.var.rate  \\\n",
       "0   may         mon       261         1         0  nonexistent           1.1   \n",
       "1   may         mon       149         1         0  nonexistent           1.1   \n",
       "2   may         mon       226         1         0  nonexistent           1.1   \n",
       "3   may         mon       151         1         0  nonexistent           1.1   \n",
       "4   may         mon       307         1         0  nonexistent           1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857         5191  no  \n",
       "1          93.994          -36.4      4.857         5191  no  \n",
       "2          93.994          -36.4      4.857         5191  no  \n",
       "3          93.994          -36.4      4.857         5191  no  \n",
       "4          93.994          -36.4      4.857         5191  no  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_marketing = pd.read_csv(data_dir + \"/bank_marketing.csv\")\n",
    "bank_marketing.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9e5ab",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Define a convenience function `ex_data_prep` to perform the data cleaning steps mentioned below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13927c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Replace the column `y` in the dataframe, by setting it to 1 if `y` is 'yes', otherwise set `y` to 0.\n",
    "2. Perform one hot encoding on the variables with data type object (i.e `job`, `marital`, `education`, `default`, `housing`, `loan`, `contact`, `month`, `day_of_week` and `poutcome`) except the target variable `y`\n",
    "3. Drop the original variables and concatenate the dummies to the original dataset\n",
    "4. Select the predictors by dropping variable `y` and save the result to a dataframe `X_ex`\n",
    "5. Save the target variable `y` column to `y_ex` variable\n",
    "6. Set the seed to 1\n",
    "7. Split the data into training, test, and validation sets with 70:15:15 ratio and save respective variables to `X_train_ex`, `X_test_ex`, `X_val_ex`, `y_train_ex`, `y_test_ex`, `y_val_ex`\n",
    "8. Scale the train, test and the validation datasets using Min max scaler and save as `X_train_scaled_ex`, `X_test_scaled_ex` and `X_val_scaled_ex` respectiely\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac022c7",
   "metadata": {},
   "source": [
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a06180d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (28831, 52) Test shape: (6178, 52) Val shape: (6179, 52)\n"
     ]
    }
   ],
   "source": [
    "def ex_data_prep(df):\n",
    "    \n",
    "    # Convert `y` to 0/1 values\n",
    "    df['y'] = np.where(df['y'] == 'yes', 1, 0)\n",
    "    \n",
    "    \n",
    "    # Perform one hot encoding\n",
    "    job_dummy = pd.get_dummies(df['job'], prefix = 'job', drop_first = True)\n",
    "    marital_dummy = pd.get_dummies(df['marital'], prefix = 'marital', drop_first = True)\n",
    "    education_dummy = pd.get_dummies(df['education'], prefix = 'education', drop_first = True)\n",
    "    default_dummy = pd.get_dummies(df['default'], prefix = 'default', drop_first = True)\n",
    "    housing_dummy = pd.get_dummies(df['housing'], prefix = 'housing', drop_first = True)\n",
    "    loan_dummy = pd.get_dummies(df['loan'], prefix = 'loan', drop_first = True)\n",
    "    contact_dummy = pd.get_dummies(df['contact'], prefix = 'contact', drop_first = True)\n",
    "    month_dummy = pd.get_dummies(df['month'], prefix = 'month', drop_first = True)\n",
    "    day_of_week_dummy = pd.get_dummies(df['day_of_week'], prefix = 'day_of_week', drop_first = True)\n",
    "    poutcome_dummy = pd.get_dummies(df['poutcome'], prefix = 'poutcome', drop_first = True)\n",
    "    \n",
    "    # Drop the original variables \n",
    "    df.drop(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', \n",
    "                    'poutcome'], axis = 1, inplace = True)\n",
    "    \n",
    "    #Concatenate the dummies to original dataset\n",
    "    df = pd.concat([df,job_dummy,marital_dummy,education_dummy,default_dummy,housing_dummy,loan_dummy\n",
    "                            ,contact_dummy,month_dummy,day_of_week_dummy,poutcome_dummy], axis=1)\n",
    "    \n",
    "    # Separate predictors from target variable.\n",
    "    X_ex = df.drop(['y'], axis=1)\n",
    "    y_ex = df['y']\n",
    "    \n",
    "    # Set the seed to 1.\n",
    "    np.random.seed(1)\n",
    "    # Split data into train, test, and validation set, use a 70 - 15 - 15 split.\n",
    "    # First split data into train-test with 70% for train and 30% for test.\n",
    "    X_train_ex, X_test_ex, y_train_ex, y_test_ex = train_test_split(X_ex.values,\n",
    "                                                    y_ex,\n",
    "                                                    test_size = .3,\n",
    "                                                    random_state = 1)\n",
    "    # Then split the test data into two halves: test and validation. \n",
    "    X_test_ex, X_val_ex, y_test_ex, y_val_ex = train_test_split(X_test_ex,\n",
    "                                                y_test_ex,\n",
    "                                                test_size = .5,\n",
    "                                                random_state = 1)\n",
    "    print(\"Train shape:\", X_train_ex.shape, \"Test shape:\", X_test_ex.shape, \"Val shape:\", X_val_ex.shape)\n",
    "    \n",
    "    # Transforms features by scaling each feature to a given range.\n",
    "    # The default is the range between 0 and 1.\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train_scaled_ex = min_max_scaler.fit_transform(X_train_ex)\n",
    "    X_test_scaled_ex = min_max_scaler.transform(X_test_ex)\n",
    "    X_val_scaled_ex = min_max_scaler.transform(X_val_ex)\n",
    "    \n",
    "    return X_train_scaled_ex, X_test_scaled_ex, X_val_scaled_ex, y_train_ex, y_test_ex, y_val_ex\n",
    "  \n",
    "X_train_scaled_ex, X_test_scaled_ex, X_val_scaled_ex, y_train_ex, y_test_ex, y_val_ex = ex_data_prep(bank_marketing)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac5bc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28831, 52)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled_ex.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da2a8cf",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### Initialize the sequential neural network model with 32 neurons for the 1st hidden layer, 32 neurons for the second layer, and appropriate input and output layers. Name the model `model`. \n",
    "##### Keep the learning rate at 0.01\n",
    "##### Compile the model using the \"adam\" optimizer, \"binary_crossentropy\" loss, and using \"accuracy\" as a metric.\n",
    "##### Print the summary of the model using the command `create_model().summary()`.\n",
    "##### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "367393e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                1696      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2785 (10.88 KB)\n",
      "Trainable params: 2785 (10.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(lr=.01):\n",
    "  opt = Adam(learning_rate=lr)\n",
    "  model = Sequential([\n",
    "          Dense(64, activation='relu', input_dim=52),\n",
    "          Dense(32, activation='relu'),\n",
    "          Dense(32, activation='relu'),\n",
    "          Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "  model.compile(optimizer=opt, loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "  return model\n",
    "create_model().summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b32f1",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Fit the model using train and validation sets with 25 epochs, default batch size, and assign it to `lr_default`, `lr_low` and `lr_high` variables for learning rate `0.01`, `0.0001`, and `0.75` respectively.\n",
    "#### Result:\n",
    "##### Default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "187b3221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "901/901 [==============================] - 1s 699us/step - loss: 0.2419 - accuracy: 0.8993 - val_loss: 0.2000 - val_accuracy: 0.9063\n",
      "Epoch 2/25\n",
      "901/901 [==============================] - 0s 511us/step - loss: 0.1983 - accuracy: 0.9093 - val_loss: 0.1959 - val_accuracy: 0.9087\n",
      "Epoch 3/25\n",
      "901/901 [==============================] - 0s 508us/step - loss: 0.1942 - accuracy: 0.9098 - val_loss: 0.1901 - val_accuracy: 0.9118\n",
      "Epoch 4/25\n",
      "901/901 [==============================] - 0s 510us/step - loss: 0.1907 - accuracy: 0.9110 - val_loss: 0.2031 - val_accuracy: 0.9071\n",
      "Epoch 5/25\n",
      "901/901 [==============================] - 0s 512us/step - loss: 0.1880 - accuracy: 0.9120 - val_loss: 0.1996 - val_accuracy: 0.9061\n",
      "Epoch 6/25\n",
      "901/901 [==============================] - 1s 568us/step - loss: 0.1867 - accuracy: 0.9120 - val_loss: 0.1934 - val_accuracy: 0.9097\n",
      "Epoch 7/25\n",
      "901/901 [==============================] - 0s 512us/step - loss: 0.1838 - accuracy: 0.9142 - val_loss: 0.2045 - val_accuracy: 0.9068\n",
      "Epoch 8/25\n",
      "901/901 [==============================] - 0s 501us/step - loss: 0.1824 - accuracy: 0.9138 - val_loss: 0.1975 - val_accuracy: 0.9112\n",
      "Epoch 9/25\n",
      "901/901 [==============================] - 0s 506us/step - loss: 0.1810 - accuracy: 0.9156 - val_loss: 0.1917 - val_accuracy: 0.9090\n",
      "Epoch 10/25\n",
      "901/901 [==============================] - 0s 506us/step - loss: 0.1786 - accuracy: 0.9162 - val_loss: 0.1958 - val_accuracy: 0.9120\n",
      "Epoch 11/25\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.1767 - accuracy: 0.9165 - val_loss: 0.1904 - val_accuracy: 0.9095\n",
      "Epoch 12/25\n",
      "901/901 [==============================] - 0s 509us/step - loss: 0.1761 - accuracy: 0.9177 - val_loss: 0.1957 - val_accuracy: 0.9071\n",
      "Epoch 13/25\n",
      "901/901 [==============================] - 0s 511us/step - loss: 0.1737 - accuracy: 0.9180 - val_loss: 0.1970 - val_accuracy: 0.9089\n",
      "Epoch 14/25\n",
      "901/901 [==============================] - 0s 550us/step - loss: 0.1730 - accuracy: 0.9174 - val_loss: 0.1993 - val_accuracy: 0.9133\n",
      "Epoch 15/25\n",
      "901/901 [==============================] - 1s 594us/step - loss: 0.1728 - accuracy: 0.9193 - val_loss: 0.1950 - val_accuracy: 0.9074\n",
      "Epoch 16/25\n",
      "901/901 [==============================] - 1s 567us/step - loss: 0.1707 - accuracy: 0.9194 - val_loss: 0.2032 - val_accuracy: 0.9076\n",
      "Epoch 17/25\n",
      "901/901 [==============================] - 0s 537us/step - loss: 0.1698 - accuracy: 0.9190 - val_loss: 0.2075 - val_accuracy: 0.9128\n",
      "Epoch 18/25\n",
      "901/901 [==============================] - 0s 503us/step - loss: 0.1687 - accuracy: 0.9205 - val_loss: 0.1973 - val_accuracy: 0.9087\n",
      "Epoch 19/25\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.1670 - accuracy: 0.9201 - val_loss: 0.1966 - val_accuracy: 0.9099\n",
      "Epoch 20/25\n",
      "901/901 [==============================] - 0s 497us/step - loss: 0.1672 - accuracy: 0.9203 - val_loss: 0.2049 - val_accuracy: 0.9110\n",
      "Epoch 21/25\n",
      "901/901 [==============================] - 0s 548us/step - loss: 0.1657 - accuracy: 0.9208 - val_loss: 0.1981 - val_accuracy: 0.9118\n",
      "Epoch 22/25\n",
      "901/901 [==============================] - 0s 495us/step - loss: 0.1647 - accuracy: 0.9218 - val_loss: 0.2045 - val_accuracy: 0.9095\n",
      "Epoch 23/25\n",
      "901/901 [==============================] - 0s 523us/step - loss: 0.1643 - accuracy: 0.9220 - val_loss: 0.1987 - val_accuracy: 0.9108\n",
      "Epoch 24/25\n",
      "901/901 [==============================] - 0s 518us/step - loss: 0.1628 - accuracy: 0.9219 - val_loss: 0.2064 - val_accuracy: 0.9123\n",
      "Epoch 25/25\n",
      "901/901 [==============================] - 0s 497us/step - loss: 0.1615 - accuracy: 0.9236 - val_loss: 0.2125 - val_accuracy: 0.9079\n"
     ]
    }
   ],
   "source": [
    "# Learning rate is 0.01\n",
    "lr_default = create_model().fit(X_train_scaled_ex, y_train_ex,\n",
    "                                epochs=25,\n",
    "                                validation_data=(X_val_scaled_ex, y_val_ex)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d19d3f",
   "metadata": {},
   "source": [
    "##### Low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a6207c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "901/901 [==============================] - 1s 562us/step - loss: 0.3378 - accuracy: 0.8879 - val_loss: 0.3082 - val_accuracy: 0.8846\n",
      "Epoch 2/25\n",
      "901/901 [==============================] - 0s 537us/step - loss: 0.2952 - accuracy: 0.8894 - val_loss: 0.2909 - val_accuracy: 0.8874\n",
      "Epoch 3/25\n",
      "901/901 [==============================] - 0s 513us/step - loss: 0.2835 - accuracy: 0.8958 - val_loss: 0.2820 - val_accuracy: 0.8925\n",
      "Epoch 4/25\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.2758 - accuracy: 0.8984 - val_loss: 0.2754 - val_accuracy: 0.8911\n",
      "Epoch 5/25\n",
      "901/901 [==============================] - 0s 493us/step - loss: 0.2689 - accuracy: 0.8993 - val_loss: 0.2693 - val_accuracy: 0.8930\n",
      "Epoch 6/25\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.2621 - accuracy: 0.9000 - val_loss: 0.2627 - val_accuracy: 0.8950\n",
      "Epoch 7/25\n",
      "901/901 [==============================] - 0s 494us/step - loss: 0.2550 - accuracy: 0.9012 - val_loss: 0.2559 - val_accuracy: 0.8966\n",
      "Epoch 8/25\n",
      "901/901 [==============================] - 0s 505us/step - loss: 0.2476 - accuracy: 0.9019 - val_loss: 0.2491 - val_accuracy: 0.8974\n",
      "Epoch 9/25\n",
      "901/901 [==============================] - 0s 538us/step - loss: 0.2402 - accuracy: 0.9031 - val_loss: 0.2416 - val_accuracy: 0.8984\n",
      "Epoch 10/25\n",
      "901/901 [==============================] - 0s 529us/step - loss: 0.2327 - accuracy: 0.9045 - val_loss: 0.2345 - val_accuracy: 0.9013\n",
      "Epoch 11/25\n",
      "901/901 [==============================] - 0s 520us/step - loss: 0.2256 - accuracy: 0.9060 - val_loss: 0.2281 - val_accuracy: 0.9026\n",
      "Epoch 12/25\n",
      "901/901 [==============================] - 0s 519us/step - loss: 0.2192 - accuracy: 0.9071 - val_loss: 0.2224 - val_accuracy: 0.9061\n",
      "Epoch 13/25\n",
      "901/901 [==============================] - 0s 508us/step - loss: 0.2139 - accuracy: 0.9087 - val_loss: 0.2171 - val_accuracy: 0.9065\n",
      "Epoch 14/25\n",
      "901/901 [==============================] - 0s 496us/step - loss: 0.2095 - accuracy: 0.9098 - val_loss: 0.2135 - val_accuracy: 0.9073\n",
      "Epoch 15/25\n",
      "901/901 [==============================] - 0s 476us/step - loss: 0.2060 - accuracy: 0.9098 - val_loss: 0.2110 - val_accuracy: 0.9066\n",
      "Epoch 16/25\n",
      "901/901 [==============================] - 0s 489us/step - loss: 0.2034 - accuracy: 0.9109 - val_loss: 0.2092 - val_accuracy: 0.9084\n",
      "Epoch 17/25\n",
      "901/901 [==============================] - 0s 483us/step - loss: 0.2014 - accuracy: 0.9118 - val_loss: 0.2079 - val_accuracy: 0.9078\n",
      "Epoch 18/25\n",
      "901/901 [==============================] - 0s 523us/step - loss: 0.1995 - accuracy: 0.9110 - val_loss: 0.2059 - val_accuracy: 0.9082\n",
      "Epoch 19/25\n",
      "901/901 [==============================] - 0s 506us/step - loss: 0.1979 - accuracy: 0.9114 - val_loss: 0.2051 - val_accuracy: 0.9068\n",
      "Epoch 20/25\n",
      "901/901 [==============================] - 0s 497us/step - loss: 0.1968 - accuracy: 0.9120 - val_loss: 0.2042 - val_accuracy: 0.9076\n",
      "Epoch 21/25\n",
      "901/901 [==============================] - 0s 494us/step - loss: 0.1953 - accuracy: 0.9124 - val_loss: 0.2037 - val_accuracy: 0.9087\n",
      "Epoch 22/25\n",
      "901/901 [==============================] - 0s 488us/step - loss: 0.1943 - accuracy: 0.9126 - val_loss: 0.2026 - val_accuracy: 0.9056\n",
      "Epoch 23/25\n",
      "901/901 [==============================] - 0s 496us/step - loss: 0.1934 - accuracy: 0.9129 - val_loss: 0.2018 - val_accuracy: 0.9071\n",
      "Epoch 24/25\n",
      "901/901 [==============================] - 1s 679us/step - loss: 0.1924 - accuracy: 0.9126 - val_loss: 0.2007 - val_accuracy: 0.9065\n",
      "Epoch 25/25\n",
      "901/901 [==============================] - 1s 648us/step - loss: 0.1915 - accuracy: 0.9137 - val_loss: 0.2004 - val_accuracy: 0.9065\n"
     ]
    }
   ],
   "source": [
    "# Learning rate is 0.0001\n",
    "lr_low = create_model(lr=.0001).fit(X_train_scaled_ex, y_train_ex,\n",
    "                                epochs=25,\n",
    "                                validation_data=(X_val_scaled_ex, y_val_ex)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e06e81e",
   "metadata": {},
   "source": [
    "##### High\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14280de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "901/901 [==============================] - 1s 639us/step - loss: 0.7818 - accuracy: 0.8853 - val_loss: 0.3621 - val_accuracy: 0.8846\n",
      "Epoch 2/25\n",
      "901/901 [==============================] - 1s 597us/step - loss: 0.3588 - accuracy: 0.8881 - val_loss: 0.3622 - val_accuracy: 0.8846\n",
      "Epoch 3/25\n",
      "901/901 [==============================] - 0s 518us/step - loss: 0.3590 - accuracy: 0.8881 - val_loss: 0.3577 - val_accuracy: 0.8846\n",
      "Epoch 4/25\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.3586 - accuracy: 0.8881 - val_loss: 0.3577 - val_accuracy: 0.8846\n",
      "Epoch 5/25\n",
      "901/901 [==============================] - 0s 484us/step - loss: 0.3582 - accuracy: 0.8881 - val_loss: 0.3578 - val_accuracy: 0.8846\n",
      "Epoch 6/25\n",
      "901/901 [==============================] - 0s 504us/step - loss: 0.3590 - accuracy: 0.8881 - val_loss: 0.3808 - val_accuracy: 0.8846\n",
      "Epoch 7/25\n",
      "901/901 [==============================] - 0s 500us/step - loss: 0.3586 - accuracy: 0.8881 - val_loss: 0.3694 - val_accuracy: 0.8846\n",
      "Epoch 8/25\n",
      "901/901 [==============================] - 0s 487us/step - loss: 0.3593 - accuracy: 0.8881 - val_loss: 0.3608 - val_accuracy: 0.8846\n",
      "Epoch 9/25\n",
      "901/901 [==============================] - 0s 484us/step - loss: 0.3571 - accuracy: 0.8881 - val_loss: 0.3577 - val_accuracy: 0.8846\n",
      "Epoch 10/25\n",
      "901/901 [==============================] - 0s 490us/step - loss: 0.3579 - accuracy: 0.8881 - val_loss: 0.3842 - val_accuracy: 0.8846\n",
      "Epoch 11/25\n",
      "901/901 [==============================] - 0s 510us/step - loss: 0.3594 - accuracy: 0.8881 - val_loss: 0.3586 - val_accuracy: 0.8846\n",
      "Epoch 12/25\n",
      "901/901 [==============================] - 0s 485us/step - loss: 0.3583 - accuracy: 0.8881 - val_loss: 0.3584 - val_accuracy: 0.8846\n",
      "Epoch 13/25\n",
      "901/901 [==============================] - 0s 480us/step - loss: 0.3613 - accuracy: 0.8881 - val_loss: 0.3689 - val_accuracy: 0.8846\n",
      "Epoch 14/25\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.3622 - accuracy: 0.8881 - val_loss: 0.3726 - val_accuracy: 0.8846\n",
      "Epoch 15/25\n",
      "901/901 [==============================] - 0s 511us/step - loss: 0.3598 - accuracy: 0.8881 - val_loss: 0.3621 - val_accuracy: 0.8846\n",
      "Epoch 16/25\n",
      "901/901 [==============================] - 0s 513us/step - loss: 0.3581 - accuracy: 0.8881 - val_loss: 0.3577 - val_accuracy: 0.8846\n",
      "Epoch 17/25\n",
      "901/901 [==============================] - 0s 505us/step - loss: 0.3611 - accuracy: 0.8881 - val_loss: 0.3588 - val_accuracy: 0.8846\n",
      "Epoch 18/25\n",
      "901/901 [==============================] - 0s 500us/step - loss: 0.3599 - accuracy: 0.8881 - val_loss: 0.3580 - val_accuracy: 0.8846\n",
      "Epoch 19/25\n",
      "901/901 [==============================] - 0s 517us/step - loss: 0.3602 - accuracy: 0.8881 - val_loss: 0.3585 - val_accuracy: 0.8846\n",
      "Epoch 20/25\n",
      "901/901 [==============================] - 0s 483us/step - loss: 0.3593 - accuracy: 0.8881 - val_loss: 0.3587 - val_accuracy: 0.8846\n",
      "Epoch 21/25\n",
      "901/901 [==============================] - 0s 484us/step - loss: 0.3578 - accuracy: 0.8881 - val_loss: 0.3587 - val_accuracy: 0.8846\n",
      "Epoch 22/25\n",
      "901/901 [==============================] - 0s 514us/step - loss: 0.3616 - accuracy: 0.8881 - val_loss: 0.3651 - val_accuracy: 0.8846\n",
      "Epoch 23/25\n",
      "901/901 [==============================] - 0s 528us/step - loss: 0.3581 - accuracy: 0.8881 - val_loss: 0.3682 - val_accuracy: 0.8846\n",
      "Epoch 24/25\n",
      "901/901 [==============================] - 1s 558us/step - loss: 0.3607 - accuracy: 0.8881 - val_loss: 0.3620 - val_accuracy: 0.8846\n",
      "Epoch 25/25\n",
      "901/901 [==============================] - 0s 524us/step - loss: 0.3604 - accuracy: 0.8881 - val_loss: 0.3582 - val_accuracy: 0.8846\n"
     ]
    }
   ],
   "source": [
    "# Learning rate is 0.75\n",
    "lr_high = create_model(lr=.75).fit(X_train_scaled_ex, y_train_ex,\n",
    "                                epochs=25,\n",
    "                                validation_data=(X_val_scaled_ex, y_val_ex)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d7eda1",
   "metadata": {},
   "source": [
    "#### Task 7\n",
    "##### Create a dataframe with the loss and accuracy for training and validation data along with their epoch and learning rates.\n",
    "##### Plot the validation accuracy and loss curves for the models with different learning rates to analyze and compare the results.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37a8b514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEGCAYAAABhMDI9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAAsTAAALEwEAmpwYAAA+AUlEQVR4nO3deZwc1XXw/d+pXmfftY6EJEZIIEACBALb2Gw2AjuCBAwCm0CAgAnEMXb8CL/xYyv4yWuT+CExefECyAbbYGFIAjJRjBMWQwI2CCMhtAtJoJGQNPvea533j+rp6R6NpJnR9PRIc76fuZ+qurX0re6ee+reqq4SVcUYY4zp5eS7AMYYY8YWCwzGGGOyWGAwxhiTxQKDMcaYLBYYjDHGZPHnuwDDUV1drTNmzMh3MYwx5pjy1ltvNapqzZGWOyYDw4wZM1izZk2+i2GMMccUEXl/MMtZV5IxxpgsFhiMMcZkscBgjDEmiwUGY4wxWSwwGGOMyWKBwRhjTBYLDMYYY7Ick79jGKtUlZ54ks5ogrKCACG/L99FOq70vr/tPQki8SSFQR/FYT8FAR8iku/iHZHrKi3dMRo6ozR0RDnQHqWhM4oAtRWF1FYUUFtRQGVRMC/747pKU1eMfW0R9rb1EE24VBcFqSoOUV0cpLwwiM8Zu++zqpJwlaSrxJNuauhNB3xCUchPyO+M6nubdJVoIkk07hJNuETiSaIJ18tLuBQGfdSUhKgqCo2p99YCQ4bMir0rmqQzkqAzmqA9EqetJ057jzccKPXOiyf7nm9RWRRkQkmIiaVhJpZ6wwklISaUhtN51cUhAr6Ra7i5rtIRSdDcHaO5K0ZLV4yWbi+19cQpCPgoLQhQGg5QWuBPDQOUpfLCgUP/43RFEzR0RNMVW2Y60BFJ5yddpTDopzDoozDooyjkVd5FIT8FQR9FQV/f/NQ8r8L33sf2SJz2nkRqGKc9kkjnZ76/vRyBopCf4lTqP14S9lMU8lEcClAc8mXNLw5nL18YPHyQSbredyQST9ITSw17xxMunZEEjZnvT2fqvemI0tgZI+ke+fknBQFfOkhMq+wNGH3DisLA4Ss3VUhEId4N8R6I96CJCK2RJA1dSfZ3xjnQlWBfe4J9nXE+bI+ztyPGvvYEPUlI4iOJgyL4cHFSKSAulYVBaop8VBf5qSz0U13op7LQR2Whn8oCP+ILEMVLEfxEkz5iLsQTLvGkS6x3mNR+0y7xpBJLJIlnzPPyXeIJLy+acEm4LomEi7pJHDeKuHHEjeNzEwQlToAEQRIEepMkiamfNorokmLiwVKCoUIKU9+PotR3ND1MfScTbqoMqXJE4y7RZEZeqoKPJTOnUykVABKD+Lx7v8OVRSFqSlKpOMSEUm+YzkulkpA/58FNcv2gHhFZDHwP8AGPqOp3+s0/AfgxUAM0A59X1frDbXPhwoU6nF8+P/fOXl7e0kBnJEFXLEFHJEFX1EsdqeGRPkdHyKpIy3rHC/rGi0M+Wrrj7G+PsL/dqxj2t3uVQ//ti0BVUYjKogBBv4PfcQj6HPw+we9zCPoEv+NN9+YHfA4Bn0MknvQq/+4YLd3xdBA41D44whH3L+CTdLAoDfvx+xyaUhVdVyw54Dari7O/0AG/Q08sSVc0QXcsSXesd+iNd0W9ynQg4YCT9foDBbHeANYd6w3iGZ9l1ufqze9NA1XKfhKU00W5dFBJB5VOB5P83Uzwd1HldOHTBK6b9FLSRVURXBzUS6IIXnJS+X6SBMSlwOdS6FcKHCXkcwk7LkHHq2AD4uIngR8XVInjEHeFuDpEk0IklXqSEHOFhHqVdRIHHB8hSRImmkoxwkQJEaNAvWlHxsYDuFyVdKCIEiCiQaIEiEmQOEES4scvLgGSWUMfSfwZyVEvXPlI4NMkPo3jMPx9jEuQLqeELqeYdopo0yJatYgWt5CmZAEtyTBBcSl0EhQ4CQqdOAWSICzxdAoRJ5QaBjWGnyTq+EEcb+j4EPGGOD7E50ccH+IEEJ8PcfwklFRrwjuwiMZ7h17eQP+vVZfczcc+8alh7beIvKWqC4+0XE5bDCLiAx4EPgnUA2+KyCpV3Zix2HeBn6rqYyJyEfBt4IZclGf7gU5ef68pdfToHUlOLgv3O7JMjfceTYR8fQGgMEBx0I8zzCZf0lWaOqPsb496QaMjwoFU4GjqjJFINYETSSWWcOmKJYn3HiEllVhqXu+RTDjgo7IoSEVhkJMmFlNRGKSyyGvyVxYFqCgMpvMqioIUBX3Eki4d6SPwxCGO0OO09XjzYgmX02rLs45cJmQcvVQMs3vBTR15d8USRGIuBUEfJWE/4cAhut9cF2IdEGnzUrQDEhFIxCAZzRimUr88TURxIx0kOxvR7mboacIXacEfaz/EhwUxN0RCAqg4iE9QvwPieNFcHCQ1Lo4vPe04guMP4vMHEMcPvgA4/r400DQQcpOE3ARoEtzelAA3QSKZIBaLEYvFiSfiJOI9xCVAwiki7lTS7YRpd8LEnRBxX5iEEybuhEk4IW/cF0adIOWFfirDPioKHMrDDsUBwaHf62nv6ya9lofjgHj7h+PrN+69HzFX6IwrnVEXNIHfjRHQGH43hl+j+JIxCtwoxW4UJxlFklEkEe37/Bxfv/fGB04gIy9j2vGDzw++EPiC3nxfEPzB1HRvXub8gPdaPa0QaYWeVgKRVsp7WimPtDI1nb/fG0bbs8++On7wh8EfSg3DGdNFffmOD9Tte//S72PveCw1dCGRSL3fGTW/A4RSCVDAVa8rLDNFShND/n8bqpy2GETkPGC5ql6amv4agKp+O2OZDcBiVd0tXvuoTVVLD7fd4bYYzFFyXXDj3hc6GU99+QeYTsZTwwQkY3156fz+4zGvou+t9NOpNWO8HYZzhCg+7x/XF4RgMRRVQUElFFalUmXfsH9+oGDATfb+z2Q25wfKM8coN+l9H9MB5vjpcR8TLQZgKrA7Y7oeWNRvmXXAn+B1N/0xUCIiVaralLmQiNwG3AYwffr0nBX4mOK6qX7kboh1pfqTM8e7INadsUw3JHogHskYRrxlE73jkexlEtG+iv8omu6DEiyBcFlfKq2FCfOy83pTqCR11Bb0/nl7K//+ec7IXwAwUOVvAeE44vigoDzfpcirsRAK/xr4/0TkJuAVYA9wUAe0qj4EPARei2E0C3gQVe8otn0PtO+Ftvrs8c4D3pcr3fQcxFB8h67MB6z4u72KfKj8BRAIe0N/yDsq9oe9YbgcSnqnM5ZJN/FTzfpBTQf6mvFOqrnv8x96PFhyXB2ZGXMsy/V/4h5gWsZ0bSovTVX34rUYEJFi4CpVbc1xubK5LsQ6vb7FSHtqmOq+iLZ5FX3bHmivT1X+e7wKPJM4UDwJyqZC1YleXiLiHXFHO6CrIdX/HTl4mMlfAMFCCBR5lXXveFFN33iw0JuXHk+lgdbLnB8o8PrHjTHmMHIdGN4EZovITLyAsBS4PnMBEakGmlXVBb6Gd4VSTtz373/G5qaNGSeH+k7wHVFv90RpECpnp46kQ335vuAAlW5wcAVTF1Cv1XBEES+5QDSVjDHjxtzKuSw7Z1lOXyOngUFVEyJyF/A83uWqP1bVDSJyL7BGVVcBFwDfFhHF60q6M2cFiqeO0nuvMui9GsLxQfqyssxhxhUSuTzSFvsBujFm7Mj57xhywa5KMsaYoRvsVUl2qGqMMSaLBQZjjDFZLDAYY4zJYoHBGGNMFgsMxhhjslhgMMYYk8UCgzHGmCwWGIwxxmSxwGCMMSaLBQZjjDFZLDAYY4zJYoHBGGNMFgsMxhhjslhgMMYYk8UCgzHGmCwWGIwxxmSxwGCMMSaLBQZjjDFZch4YRGSxiGwRke0ics8A86eLyEsi8raIvCMil+e6TMYYYw4tp4FBRHzAg8BlwCnAdSJySr/Fvg78UlXPAJYC389lmYwxxhxerlsM5wDbVXWHqsaAlcAV/ZZRoDQ1XgbszXGZjDHGHEauA8NUYHfGdH0qL9Ny4PMiUg+sBv5yoA2JyG0iskZE1jQ0NOSirMYYYxgbJ5+vAx5V1VrgcuBnInJQuVT1IVVdqKoLa2pqRr2QxhgzXuQ6MOwBpmVM16byMt0C/BJAVV8HwkB1jstljDHmEHIdGN4EZovITBEJ4p1cXtVvmQ+AiwFE5GS8wGB9RcYYkyc5DQyqmgDuAp4HNuFdfbRBRO4VkSWpxb4C/LmIrAN+AdykqprLchljjDk0f65fQFVX451Uzsz7Rsb4RuCjuS6HMcaYwRkLJ5+NMcaMIRYYjDHGZLHAYIwxJosFBmOMMVksMBhjjMmS86uSjDHmaMTjcerr64lEIvkuyjEjHA5TW1tLIBAY1voWGIwxY1p9fT0lJSXMmDEDEcl3ccY8VaWpqYn6+npmzpw5rG1YV5IxZkyLRCJUVVVZUBgkEaGqquqoWlgWGIwxY54FhaE52vfLAoMxxpgsFhiMMcec4uLiUX29j3zkIyOynZdffpmysjIWLFjA3Llz+eu//usjrvPMM8+wcePGEXn9wbLAYIwZ9xKJxGHnv/baayP2Wueffz5r167l7bff5rnnnuN//ud/Dru8BQZjjBmm9957j8WLF3PWWWdx/vnns3nzZgB+9atfsWjRIs444wwuueQS9u/fD8Dy5cu54YYb+OhHP8oNN9zA8uXLufnmm7nggguYNWsWDzzwQHrbvS2Ul19+mQsuuICrr76auXPn8rnPfY7em0GvXr2auXPnctZZZ/HFL36Rz3zmM4ctb0FBAQsWLGDPHu8RNQ8//DBnn3028+fP56qrrqK7u5vXXnuNVatW8dWvfpUFCxbw3nvvHXI/R5SqHnPprLPOUmPM+LBx48aD8oqKig7Ku+iii3Tr1q2qqvq73/1OL7zwQlVVbW5uVtd1VVX14Ycf1i9/+cuqqvrNb35TzzzzTO3u7k5Pn3feeRqJRLShoUErKys1Fotlvd5LL72kpaWlunv3bk0mk3ruuefqq6++qj09PVpbW6s7duxQVdWlS5fqpz/96YPK+NJLL6Xzm5ub9cwzz9QPP/xQVVUbGxvTy/3N3/yNPvDAA6qqeuONN+pTTz11xP0czPsGrNFB1LH2OwZjzDGvs7OT1157jc9+9rPpvGg0Cni/g7j22mv58MMPicViWdf2L1myhIKCgvT0pz/9aUKhEKFQiAkTJrB//35qa2uzXuucc85J5y1YsIBdu3ZRXFzMrFmz0tu+7rrreOihhwYs66uvvsr8+fPZtm0bX/rSl5g0aRIA7777Ll//+tdpbW2ls7OTSy+9dEj7OZIsMBhjjnmu61JeXs7atWsPmveXf/mXfPnLX2bJkiW8/PLLLF++PD2vqKgoa9lQKJQe9/l8A557GMwyh3P++efz3HPPsXPnTs4991yuueYaFixYwE033cQzzzzD/PnzefTRR3n55ZeHtJ8jyc4xGGOOeaWlpcycOZOnnnoK8LrI161bB0BbWxtTp04F4LHHHsvJ68+ZM4cdO3awa9cuAJ588skjrjNz5kzuuece7rvvPgA6OjqYPHky8Xicxx9/PL1cSUkJHR0dwOH3cyRZYDDGHHO6u7upra1Np/vvv5/HH3+cFStWMH/+fObNm8ezzz4LeCeZP/vZz3LWWWdRXV2dk/IUFBTw/e9/P31SuKSkhLKysiOu94UvfIFXXnmFXbt28a1vfYtFixbx0Y9+lLlz56aXWbp0Kf/wD//AGWecwXvvvXfI/RxJojl+vLKILAa+B/iAR1T1O/3m/yNwYWqyEJigquWH2+bChQt1zZo1OSitMWas2bRpEyeffHK+i3FEnZ2dFBcXo6rceeedzJ49m7vvvjtv5RnofRORt1R14ZHWzWmLQUR8wIPAZcApwHUickrmMqp6t6ouUNUFwD8D/5rLMhljTC48/PDDLFiwgHnz5tHW1sbtt9+e7yINW65PPp8DbFfVHQAishK4AjjUrzWuA76Z4zIZY8yIu/vuu/PaQhhJuT7HMBXYnTFdn8o7iIicAMwEXsxxmYwxxhzGWDr5vBR4WlWTA80UkdtEZI2IrGloaBjlohljzPiR68CwB5iWMV2byhvIUuAXh9qQqj6kqgtVdWFNTc0IFtEYY0ymXAeGN4HZIjJTRIJ4lf+q/guJyFygAng9x+UxxhhzBDkNDKqaAO4Cngc2Ab9U1Q0icq+ILMlYdCmwUnN97awxxpgjyvk5BlVdraonqeqJqvp3qbxvqOqqjGWWq+o9uS6LMcaMpJ07d7Jo0SLq6uq49tpricViALzyyiuceeaZ+P1+nn766TyXcujG0slnY4w5pixbtoy7776b7du3U1FRwYoVKwCYPn06jz76KNdff32eSzg8dhM9Y8wx629/tYGNe9tHdJunTCnlm38074jLqSovvvgiTzzxBAA33ngjy5cv54477mDGjBkAOM6xeex9bJbaGGPyrKmpifLycvx+7/i6trY2/dCdY521GIwxx6zBHNmbobMWgzHGDENVVRWtra3p5zHU19enb+99rLPAYIwxwyAiXHjhhemrjh577DGuuOKKPJdqZFhgMMaYIbr88svZu3cv9913H/fffz91dXU0NTVxyy23APDmm29SW1vLU089xe233868ecdWl5edYzDGmCFavXp1evyNN944aP7ZZ59NfX39aBZpRFmLwRhjTBZrMRhjzChYv349N9xwQ1ZeKBTi97//fZ5KdGgWGIwxZhScdtpprF27Nt/FGBTrSjLGGJPFAoMxxpgsFhiMMcZkscBgjDEmiwUGY4wZpkM9jyEajXLttddSV1fHokWL2LVrV3qdb3/729TV1TFnzhyef/75dP7NN9/MhAkTOPXUU0d7Nw5igcEYY4bpUM9jWLFiBRUVFWzfvp27776bZcuWAbBx40ZWrlzJhg0b+PWvf81f/MVfkEwmAbjpppv49a9/nbd9yWSXqxpjjl3/cQ/sWz+y25x0Glz2nSMudrjnMTz77LMsX74cgKuvvpq77roLVeXZZ59l6dKlhEIhZs6cSV1dHW+88QbnnXceH//4x7NaFvlkLQZjjBmGwz2PYc+ePUybNg0Av99PWVkZTU1NWfn91xlLBtViEJHPAr9W1Q4R+TpwJvB/VPUPg1h3MfA9wAc8oqoHhWIRuQZYDiiwTlWPzefhGWNG1yCO7M3QDbbF8L9TQeFjwCXACuAHR1pJRHzAg8BlwCnAdSJySr9lZgNfAz6qqvOALw2++MYYkx+Hex7D1KlT2b17NwCJRIK2tjaqqqqy8vuvM5YMNjAkU8NPAw+p6r8DwUGsdw6wXVV3qGoMWAn0v2H5nwMPqmoLgKoeGGSZjDEmbw73PIYlS5bw2GOPAfD0009z0UUXISIsWbKElStXEo1G2blzJ9u2beOcc87J2z4cymADwx4R+RFwLbBaREKDXHcqsDtjuj6Vl+kk4CQR+R8R+V2q6+kgInKbiKwRkTUNDQ2DLLYxxoy8Iz2P4ZZbbqGpqYm6ujruv/9+vvMdr8tr3rx5XHPNNZxyyiksXryYBx98EJ/PB8B1113Heeedx5YtW6itrU1f4ZQPoqpHXkikEFgMrFfVbSIyGThNVX9zhPWuBhar6q2p6RuARap6V8YyzwFx4BqgFnglte3WQ2134cKFumbNmiOW2xhz7Nu0aRMnn3xyvotxzBnofRORt1R14ZHWHWyLYTLw76mgcAHwWeDgp1McbA8wLWO6NpWXqR5YpapxVd0JbAVmD7JcxhhjRthgA8O/AEkRqQMewqvsnxjEem8Cs0VkpogEgaXAqn7LPANcACAi1XhdSzsGWS5jjDlu3XnnnSxYsCAr/eQnP8n56w72B26uqiZE5E+Af1bVfxaRt4+0Umqdu4Dn8S5X/bGqbhCRe4E1qroqNe9TIrIR7yT3V1W1aXi7Y4wxx48HH3wwL6872MAQF5HrgD8F/iiVFxjMiqq6GljdL+8bGeMKfDmVjDHG5Nlgu5L+DDgP+DtV3SkiM4Gf5a5Yxhhj8mVQgUFVNwJ/DawXkVOBelW9L6clM8YYkxeDvSXGBcBjwC5AgGkicqOqvpKzkhljjMmLwXYl/V/gU6r6CVX9OHAp8I+5K5Yxxox9559/fvpqoSlTpnDllVcC8PLLL1NWVpaed++99+a3oEM02JPPAVXd0juhqltFZFAnn40x5nj16quvpsevuuqq9C0xwAsazz33XD6KddQGGxjWiMgjwM9T058D7KfHxpi8uu+N+9jcvHlEtzm3ci7Lzlk2pHXa29t58cUXR+U3BqNhsF1JdwAbgS+m0sZUnjHGjHvPPPMMF198MaWlpem8119/nfnz53PZZZexYcOGPJZu6AbVYlDVKHB/KhljzJgw1CP7XPnFL37Brbfemp4+88wzef/99ykuLmb16tVceeWVbNu2LY8lHJrDthhEZL2IvHOoNFqFNMaYsaqxsZE33niDT3/60+m80tJSiouLAe9OrPF4nMbGxnwVcciO1GL4zKiUwhhjjlFPP/00n/nMZwiHw+m8ffv2MXHiRESEN954A9d1qaqqymMph+awgUFV3x/MRkTkdVU9b2SKZIwxY9vll1/OI488wpQpU1i5ciX33HNP1vynn36aH/zgB/j9fgoKCli5ciUikqfSDt2gnsdwxI2IvK2qZ4xAeQbFnsdgzPhhz2MYntF4HsORHH10McYYMyYM9ncMxhhjjkJTUxMXX3zxQfkvvPDCmDv/MFKB4djpPDPGmDyoqqpi7dq1+S7GoIxUV9INI7QdY4wxeXbYFoOIdDDw+QPBe8ZOKd7IuzkomzHGmDw40uWqJaNVEGOMMWPDkLqSRGSCiEzvTYNcZ7GIbBGR7SJyzwDzbxKRBhFZm0q3DrQdY4wxo2NQgUFElojINmAn8Fu8B/b8xyDW8wEPApcBpwDXicgpAyz6pKouSKVHBlt4Y4zJp507d7Jo0SLq6uq49tpricViALzyyiuceeaZ+P1+nn766TyXcugG22L4FnAusFVVZwIXA78bxHrnANtVdYeqxoCVwBVHWMcYY44Jy5Yt4+6772b79u1UVFSwYsUKAKZPn86jjz7K9ddfn+cSDs9gL1eNq2qTiDgi4qjqSyLyT4NYbyqwO2O6Hlg0wHJXicjHga3A3aq6u/8CInIbcBt4b7oxxvztrzawcW/7iG7zlCmlfPOP5h1xOVXlxRdf5IknngDgxhtvZPny5dxxxx3MmDEDAMcZqQs/R9dgS90qIsXAq8DjIvI9oGuEyvArYIaqng78J96zpQ+iqg+p6kJVXVhTUzNCL22MMcPT1NREeXk5fr93fF1bW8uePXvyXKqRMdgWw0tAGfBXwOdT44N5iOkeYFrGdG0qL01VmzImHwH+fpBlMsaMc4M5sjdDN9gWgx/4DfAyUIJ3srjpsGt43gRmi8hMEQkCS4FVmQuIyOSMySXApkGWyRhj8qaqqorW1lYSiQQA9fX1TJ06Nc+lGhmDCgyq+reqOg+4E5gM/FZE/msQ6yWAu4Dn8Sr8X6rqBhG5V0SWpBb7oohsEJF1eI8NvWkY+2GMMaNKRLjwwgvTVx099thjXHHF8XFtzZBuuy0ik4DP4h35l6TOC4w6u+22MePHWLztdu/zGCKRCEuXLqW5uZkzzjiDn//854RCId58803++I//mJaWFsLhMJMmTRr15z4fzW23B3WOQUT+ArgGqAGeAv5cVTcOo6zGGHPMW716dXr8jTfeOGj+2WefTX19/WgWaUQN9uTzNOBLqro2h2UxxhgzBgwqMKjq13JdEGOMOZ6tX7+eG27IvhF1KBTi97//fZ5KdGj2oB5jjBkFp5122rh7HoMxxpjjhAUGY4wxWSwwGGOMyWKBwRhjTBYLDMYYM0yHeh5DNBrl2muvpa6ujkWLFrFr1670Ot/+9repq6tjzpw5PP/88+n8m2++mQkTJnDqqaeO9m4cxK5KMsYcu/7jHti3fmS3Oek0uOw7g1q093kMS5cu5Qtf+AIrVqzgjjvuYMWKFVRUVLB9+3ZWrlzJsmXLePLJJ9m4cSMrV65kw4YN7N27l0suuYStW7fi8/m46aabuOuuu/jTP/3Tkd2fYbAWgzHGDEPv8xiuvvpqwHsewzPPPAPAs88+y4033gjA1VdfzQsvvICq8uyzz7J06VJCoRAzZ86krq4u/cvpj3/841RWVuZlX/qzFoMx5tg1yCP7XDjc8xj27NnDtGneEwf8fj9lZWU0NTWxZ88ezj333PQ2xuozHKzFYIwxJosFBmOMGYbDPY9h6tSp7N7tPaE4kUjQ1tZGVVVVVn7/dcYSCwzGGDMMh3sew5IlS3jsMe8pxU8//TQXXXQRIsKSJUtYuXIl0WiUnTt3sm3bNs4555y87cOhWGAwxpghuvzyy9m7dy/33Xcf999/P3V1dTQ1NXHLLbcAcMstt9DU1ERdXR33338/3/mOdy5k3rx5XHPNNZxyyiksXryYBx98EJ/PB8B1113Heeedx5YtW6itrWXFihV5278hPahnrLAH9RgzfozFB/UcC47mQT3WYjDGGJMl54FBRBaLyBYR2S4i9xxmuatEREXkiNHMGGPGgzvvvJMFCxZkpZ/85Cc5f92c/o5BRHzAg8AngXrgTRFZ1f+xoCJSAvwVMPaeWGGMMXny4IMP5uV1c91iOAfYrqo7VDUGrASuGGC5bwH3AZEcl8cYY8wR5DowTAV2Z0zXp/LSRORMYJqq/nuOy2KMMWYQ8nryWUQc4H7gK4NY9jYRWSMiaxoaGnJfOGOMGadyHRj2ANMypmtTeb1KgFOBl0VkF3AusGqgE9Cq+pCqLlTVhTU1NTkssjHGjG+5DgxvArNFZKaIBIGlwKremarapqrVqjpDVWcAvwOWqKr9SMEYM+adf/756auFpkyZwpVXXgnAyy+/TFlZWXrevffem9+CDlFOr0pS1YSI3AU8D/iAH6vqBhG5F1ijqqsOvwVjsnXFu1ixfgVr9q9h6ZylLJ65GEfs5zjj1X1v3Mfm5s0jus25lXNZds6yQS376quvpsevuuqq9C0xwAsazz333IiWbbTk/LbbqroaWN0v7xuHWPaCXJdnPOqIdfDEpif4t+3/xqSiSSycuJCzJp7F/Jr5FAYK8128QXHV5dntz/LA2w/Q2NPIlKIpLHt1GT/d+FO+svArnD3p7HwX0Yxj7e3tvPjii6PyG4PRYM9jOI61x9p5fOPj/GzTz+iIdXDu5HNpj7Xz8PqH+dE7P8IvfuZVz2PhxIUsnLSQBTULKA4W57vYB3lr/1vc98Z9bGrexOk1p/O9C7/HqdWn8tyO53jgDw9w8/M3c8G0C7j7rLuZVTYr38U1o2iwR/a59swzz3DxxRdTWlqaznv99deZP38+U6ZM4bvf/S7z5s3LYwmHxgLDcagt2sbPNv6Mxzc9Tme8k4umXcQX5n+Bk6u8+6Z0xjp5+8DbrNm/hjX71/DYhsdY8e4KHHE4ufLkdKA4Y8IZlIXK8rYf9R31/ONb/8hv3v8NEwsnct/593HZzMsQEQCWnLiET53wKX6+6ec8sv4R/uTZP+Hqk67mjvl3UFVQlbdyZ+pJ9NAaaaUl2kJLpIWWaAutkVaaI820RltpjbYS9oWZXzOfBRMWUFdeh8/x5bvYZoh+8YtfcOutt6anzzzzTN5//32Ki4tZvXo1V155Jdu2bctjCYfGbqJ3HGmNtPLTjT/lic1P0BXv4pLpl3D7/NuZWzn3sOt1x7tZ17DOCxT71rC+cT1xN44g1FXUcXLlycypmMPcyrnMqZyT82DRFe/ikfWP8NMNP8Xn+PizU/+Mm+bdRIG/4JDrNPU08cN1P+SprU8R9oe55dRb+Pwpnz/sOiOlJdLCuoZ1rD2wls0tm2nu6av0exI9A67jiEN5qJyKUAWt0VaaIk0AFPoLOa3mNBbULGDBhAWcXnM6pcHSAbcxXoyVm+ipKq66JDXpJdcbHmg4wKL5i1i3bR2lRaUEnSABXwCf+NIHMTNmzGDNmjVUV1ePWnmP5iZ61mI4DrREWnhsw2P8YvMv6En08MkTPsnt82/npIqTBrV+YaCQ86acx3lTzgMgkoiwvnE9a/avYd2Bdby29zVWvdd3ncCkoknMrfCCxNzKucypmMPUkqlHfRK4/3mEz8z6DH915l8xqWjSEdetKqjib879G64/+Xr+6a1/4oG3H2DllpV88Ywv8plZnxmxo3BXXXa07mBtw1rWHljLuoZ17GrfBYBf/NRV1FFTUMPsitlUhCooD3uVf0XYS+WhcirDlZQES9Lvl6qyp3MPaxvWsu7AOtY1rOPh9Q/jqgvAiWUnsmDCgnSrYkbpjHSFY46eqhJ348SSMWJujHgyTsyNpSv+pCZxXS8gDOTJlU9y/iXn0+62097RDkDj/kZqJtYQ8ofY+PZG4sk4UiR0xjoJ+oL4Hf+YvmhiXLUYVqxfwbPvPUv/fVa86d58RbOWKQoUUV1YTU1BDTUFNVQXVFNTmD0e8oWOYo+GpznSzKMbHmXl5pVEEhEunXEpt59+O3UVdSP+Wo09jWxt3srmls1sad7CluYt7Gzfma68igJFzKmYw0kVJ1FbUktpsJTSUKk3DJZSFiqjNFhKgb9gwEqt/3mEZWcv4/Sa04dd3rf2v8V33/wu7za9y5yKOXxl4VfSgW8ouuJdrG9cz9oDa1nbsJZ3DrxDR7wDgIpQBfMnzE8f3c+rmkfYHx52mTN1x7tZ37g+3RJZ17CO9phX6ZSFypheMp2qgirv+5f6HlYVVGWN5+M7mQsj0WJw1U1X+LFkLB0EYskYcTee9f8uIgScAD7Hh0/6kuM46fFrr7yW7//o+9ROreXSiy/lfy37XyxevDgdYL7/4Pf5ycM/wfE7hEIhvvqtr7Lg7AVZZQr4At7riA+/4/e27fjwi9+bTr3+cIPI0bQYxlVgWPXeKl6pfwUAQbKGfYNUvgiCoCidsU4aehpo7G6kKdI04JFDSbAkHTgqCyrxi9cYSwcd+t7nzADUl5k5qgOPZ3xWSU3y2t7XiCajLJ6xmNtOv40Ty08c0vtxtCKJCO+1vsfm5s1sbt7M1patbGnZQle865Dr+MWfFTBKQiUkkgl+v+/3TCycyJfP+nLWeYSj4arL87ue53t/+B57OvcwsXAifsf7XARJv0bvePq7gPf5u+qyu2M3rroIwonl3pF7byCYXjJ91I7cXXXZ1baLdQ1ei+LDrg9p7GmksaeRlkhL9ncppTRYSnVBNdUF1ZSHynHVJeEmiLvxvpSMk9AE8WRfXu8yrrr4HX9WRdVbgQWcQHo8cx7qfTd7u1xcddNH3ll5GfMyD8wUr7tGUbw/5RuzvsHkWZMH3MfBSrrZ/7OOOAR9QYK+IAEn4I07fdMj/bmqKgk30ReYUi2ThJsgoQmSbpKEmzjk+o446cAxqXASRcGiI76mBYZRlHSTtERbaOxppKG7wRv2NKT/SRu6G2iKNKWPpCE72Awmr79DLXNq9ancetqtzCybOTI7NwJUlY54B+3RdtpjqZQa74h1ZE33jvckerh0xqXcdOrhzyMMVywZ45dbfsmm5k3pyqd/ZdRbCUF2i3FW+SwW1CzgtJrTxmxff9yN0xJpoaGngaaepqzvZlOkiYbuBlqjrV4l7/gJOIF08vv6pvvPExGvwtKEV4G5CZKaTI/35vdWagk3gYikKzFHnPRRb1Ze5tBxvMCcEagdcbKC9aWFl3JC3QmDei8O9T/kc3xZlX9m//9YoapZ5y4y3+/MYU1BzaAuM7dzDKPI5/jSR2FHOqk7HolIujUwVgR9QT5/yufzXYycCTgBJhROYELhhHwXJSc2bdrElOIp+S7GUWtqauLiiy8+KP+FF16gqqoKEUm3zvIt/yUwxpgjUNUxd4Q/VFVVVaxdu3ZUXutoe4LG7mlxY4wBwuEwTU1NR13ZjReqSlNTE+Hw8C+EsBaDMWZMq62tpb6+Hrvd/uCFw2Fqa2uHvb4FBmPMmBYIBJg5c+xcYDEeWFeSMcaYLBYYjDHGZLHAYIwxJosFBmOMMVksMBhjjMligcEYY0yW8RUYOg9Ad3O+S2GMMWNazgODiCwWkS0isl1E7hlg/hdEZL2IrBWR/xaRU3JWmP/5Hnz3JHjy87DlPyAZz9lLGWPMsSqnP3ATER/wIPBJoB54U0RWqerGjMWeUNUfppZfAtwPLM5JgRZ8DlThnSdh06+gqAZOuwYWXA+TTs3JSxpjzLEm1y2Gc4DtqrpDVWPASuCKzAVUtT1jsgiO4qbrRzLxFFj8/8JXNsN1K2H6ufDGQ/DDj8IPPwa/+wF0Nebs5Y0x5liQ61tiTAV2Z0zXA4v6LyQidwJfBoLARQNtSERuA24DmD59+tGVyheAOZd5qbsZ1j8Nax+HX98Dv/k6zL7Ua0XM/hT4g0f3WsYYc4zJ6YN6RORqYLGq3pqavgFYpKp3HWL564FLVfXGw203Zw/q2b8R1j0B656ErgNQWAWnfRZOuhQmzYeiqpF/TWOMGSVj5UE9e4BpGdO1qbxDWQn8IKclOpyJp8Cn/g9cvBzee9FrRaz5Mfz+h9780qkweT5MOh0mn+4Ny2rhGL9PvDHGZMp1YHgTmC0iM/ECwlLg+swFRGS2qm5LTX4a2Ea++fxw0qe8FGmDvW/Dh+/Avnfgw3XeFU29p0IKKjICxXxvWFUHji+vu2CMMcOV08CgqgkRuQt4HvABP1bVDSJyL7BGVVcBd4nIJUAcaAEO24006sJlMOsCL/WKdcH+DV6Q2PeOFzR+/yNIxrz5/gKoOhEqZ0LlLKg8MTWcBSWTwRlfPx8xxhxbcnqOIVdydo7haCTj0LDFCxT73oXm96B5B7Ts6gsY4AWNdMDIDBwzva4qa2kYY3JkrJxjGD98Ae+3EP1/D+Emoa3eCxKZqWk7bPtPSEb7lnUCUD4Nyk+AihlQ0Tuc4eUVVNj5DGNMzllgyDXHl6rgT4ATL8ye57rQsbcvWLS877UwWnbBplXQ3ZS9fKgMKqb3BYuKVIuj6kQorbUuKmPMiLDAkE+O413VVFYLMz9+8PxIO7S+nx0wWt/3uqy2/ia7teELecGi6sS+YNHbTVU61YKGMWbQLDCMZeFSmHSal/rLbG00vZc6p7HTG9/+QnbQ8IczWhezvKumKk/0gkfJZOueMsZkscBwrDpca6M3aKQDxg5o2uGNb/+v7KARKEwFiVl9waLyRC94FFVb0DBmHLLAcDzKDBqzPpE9z01C+x7v5HfTe30tjn3vwuZ/BzfRt2yoNNXKqPMCRu+w8kQoKB/VXTLGjB4LDOON44Py6V46sd9tqZIJ7xxGZvdU03aofxPe/Rey7m9YWH1wsKiq8wJJsHBUd8kYM7IsMJg+Pn+qsj8RZn8ye14i6p387m1p9A57bx2SqbQWauZ4qfokqJnrjRdWjtquGGOGzwKDGRx/qK+y7y/a2ffbjKb3oGkbNGyGt16HeHffcoXVqSBxElTP6duenQA3ZkyxwGCOXqjYu0fU5NOz810X2uu9y2sbtkBjavjuv0KkNWP9Uq8bqvokqK6DqtneeOUsCIRHdVeMMRYYTC45Tt/5jMyuKVXoavBaFb1Bo2kb7PpveGdl33KSWr83UFSngkfVbCieYK0MY3LEAoMZfSJexV484eBLbWNdXpdU47ZU2toXNBI9fcuFSr37S1Vk3Heqd9xuVGjMUbHAYMaWYJH3zIvJ87PzXde7zLZxa1/gaNkJ+9bD5ueyL7P1h7NvGdIbNCpmeJfwWveUMYdlgcEcGxwndYPBaVB3cfa8ZMI7l9G8w/v1d+9dbZt3wI6Xs1saAEUTvO2UpbZXNj17Olw2WntlzJhkgcEc+3z+vhsLnthvnip07u+7SWHbbmj9wBvuW+89dCnzl+Dg3aywN1CU1ULZVO8S3LKp3n2nSqd4d9M15jhlgcEc30SgZJKXTvjIwfNd1zsRnhkwWnf3TX/wmvcUv+yNetsrnTpA0Jjq3UqksApCJXaC3ByTLDCY8c1xoGSil2oP8fySaKd3fqNtN7TtSY3v8bqv9m/w7nTbv7sKvOdrFFalUqU37A0amfkFFRAs8QJJqAQCBRZQzIBUFVVwnNx+PywwGHMkoeJD/7gPvO6qnhbvgUwdH3rP0ehq9IbdTdDd7A33b/CGPS1k3V6kP/F5rxkq7QsWweK+8VCJd5I+UODdBDE9LDw4L5jK94e9HynaEwLHvJ5Ykt0t3XzQ1O0Nm7vZ3dzN7uYePmju5oc3nMUnTqrJaRlyHhhEZDHwPbxnPj+iqt/pN//LwK1AAmgAblbV93NdLmNGjEiqRVB58I/8BuImoae1L3D0tECsE6LtXusk2tGXYqlhpNULPL358S5Qd+hldfzeszv8QfCFUH8Q1wmRkAAxAkTxE1U/3a4f1wlRUlpGRXk5BYXFECjqCzTpwNQvzxfwWkq+gPdavSk9bYEJoLU7xtb9nexq6mJ3c1/l/0FzD42d2ee8ioI+plUWMr2qkI/NrmZiaSjn5ctpYBARH/Ag8EmgHnhTRFap6saMxd4GFqpqt4jcAfw9cG0uyzWWuK6yYW87Oxo7KS0IUFkYpKIwSHlRgJKQH8lDl8K+tghv7GrmzZ3N7G7pZlpFIbNqiphZXcSJNcVMKS/Al+Om7HHN8UFRlZeGS9V7lni8G+I9EOvuG4/3jXd2tnOguYXW1lYikR6ikR5i0QiJWIRkdwQ3EcGvcUIkCBInSA8hiRGSBCFiuE0xeojgSIwQsSOX64gkI0gEvPciM5ikx735SfHTlRC6EkJ7TGiNKjHXIRwKUBgKUhQOUhQOUVwQIBwMIo7Pa3GJ421bHC/5AuALZgyD4PhRX4DOhENDt8v+LmVfp8uHnQkau5XiwjDVZUXUlBYxoayIiRUlTCgvJBgIZpQ/FezSwS+Q9Ruatu44Ww90sHV/B9v2d7LtQAdb93fS0NFX+fscYUp5mGkVhVxy8gSmVRZ6gaCykGkVBVQWBUe9Hsh1i+EcYLuq7gAQkZXAFUA6MKjqSxnL/w74fK4K89LmA6zd3Up1SYjqoiBVxSGqi71haXj0KuGGjiivbmvgla0NvLqtkaaugf/h/I5QXhikojBARWGQiiJv2Js3qSzM9NQXaLhfHlXlvYYu3tzVnE67m73+8qKgj+lVRby1q4WOaN/vBIJ+hxlVhcysLmJWTbE3TI1XFAbyEszGukTSpSuapDOWoCvam5J0RhM4AjUlIWpKQlQXhwgHBnFULeJ1DflDUFBBJJ5k+4FOtjR0sHlfO5v3dbB5XwcNHQXARAAcgariEDXFIWomeK/V+7o1JSGKM6ZLw36iCZf1e9p4+4MW3v6glbXvN9LW0UkhUcr8MeZPCHDaxACnVAc4qcKhIhCHZBzcuPe7kmTCG7q9+cmMeRnTyThuMk5Xdw8d3T109fTQ3REhGo2SiHfjlyQBkoQkyaSAEiBJsiuJ25HEUZeYuLSi+HEJOIpfvOQTFwfFwYVkHNHkwW8jUJJKs/rPbAJ2D/2zTuIjLn5i6qUp+KlRP+eKH/GH8AeDBCeGCYXChENBQgE/jpMKYFEHPhTY53ifcW9gyxw/9y9g6plDL9gQ5DowTCX7ra0HFh1m+VuA/xhohojcBtwGMH369GEV5vUdTTz0yo4B5wV9DlXFQaqKg1QXh6gqClFdEqS6KMSksjBTKwqorSigpjg05IovnnR56/0WXtnawG+3NrBhbzsAVUVBzp9dzSfm1HDqlDLaIwlau2O0dMdp6YrR0m98V2M3f+hupbU7RjyZ3Uedbm72pqq+8akVBYT8XmWTSLps/LCdN3Z6QWDNrpZ0YKoqCnL2jEpu+shMzplRycmTS/D7HFSVxs4YOxo62dnYxY7GLnY0dLH9QCcvbj6QVZayggAzqgqprSikNvWe9Y5PrSigMDi8r1x3LEFjR4zGrihNnTG6YwkmlYaZUl7AxNIwQf/I/NLZdZXGzih72yLsa+uhK5oklnSJxr1hLOESTfQNe8d7l4kmXLqiCTqjCbpjyfR4NDH4bp/SsD+jwg57FXlGBV5VFGRfWyQrAOxs7CLpep9D0O9w0sRiPj67hrmTSpg7uYTZE0qoKQkNqaUXDvg4e0YlZ8/ouyvu3tYe3v6g1QsWu1t5bn0bsdS+TS4rTr+G35HU0Mme9gk+x0lPJ5Iu2xs62bq/M70dnyPMrC5i7rQSr/yTSpkzqYTaioKs/71E0mVPaw/vNXaxq7GLXU3d7GzsYldTF/UtPen3o5fgEiBJkc/lhAo/M8oCnFAeYFp5gNpSP1NLfEwscgiS9FpjboJkMkFrZw9N7Z20dPTQ3NlNW1cPbZ3dtHdF6OyJ4MPFTwI/SYKSoMBxmVAkVBc4VIWhIgQ1QaXQ5yLJuLft3uRGIOoC6nUNphP9pjOWybzPWI6I6mFOgh3txkWuBhar6q2p6RuARap61wDLfh64C/iEqkb7z8+0cOFCXbNmzbDKFE+6tHTFaOyM0dgZpSlV0TR0esPG1LCpM0pjZ4xYMvsfOuR3UkGikKnlBVmV37SKAqqLQziOsLu5m9+mAsHr7zXRGU3gc4SzplfwiTk1fHx2DfOmlA7r6gJVpTOaYF9bhA9S/ZO9fZTvN3njmRWRCEwuDVNTGmb7/g66Yt6R0/TKQs6eUck5Mys4e0YlM6uLhhz0EkmX+pYedjR2sqPBCxq7m7upb+lhT0vPQe9fVVEwK1jUVhQwuayAnngy/d43pt773s+nsSNGT/zgo73M/ZtQEmJKeQFTyguYWl7AlLIwk3vHywuoKPR+d9DWE2dva4S9rT182NbD3rYIH7b2eHltPexvjxwUdAd6vaDPIeh3CPl9hPy9496wKOinKOSnOORLDb3popCfomD/PB/JVDBq6MhI/aZ7P7P+plUWMHdSKXMnlTAnVYnOqCrE7xudW4JEE0k2fdjB2x+0sHZ3K+09cRKuknS139AlkfSmM+cBzKop4uTJpcyZ6O1D3YTiwbWaDiOWcKlv6WZXUxc7G7spDPo4obKQE6qLmFQaHrGu0HjSZV9bhN0t3UTjLnUTiplaXpDzq4aGS0TeUtVDXH6XsVyOA8N5wHJVvTQ1/TUAVf12v+UuAf4ZLygcONJ2jyYwDIWq0h7xKuD6lm72tPZQ39JDfUt3athDc79uoKDPoawwkO5DnFpekA4EH6mrojSc+x9GqSoNHdGsoPFBczf72iLUTShOHwVOKsvtrSFcV2nojGa9X5njAwUOR6CyyOviq87o6qvKmK4uDlEQ8LGvPcKHrRH2tPawt7WHvW1eBb+ntSd99NkrHHBwROjuV8EGfMLE0jBTygqYUu4FkyllYSaXFTCpLExpOEAwVeH3Vv5+R0a9u6wrmkgFzCgNHTEmlIY4aWIJxSG7sNAM3lgJDH5gK3AxsAd4E7heVTdkLHMG8DRey2LbYLY7WoFhMLpjCfb0q/QaOqKcOrWMT8ypYdYwjsLHi97Asbe1h6KQn6oi78T70R5tqSrNXbF0kNibSgpMLgunWxZTysLpFp4x48FgA0NODzdUNSEidwHP412u+mNV3SAi9wJrVHUV8A9AMfBUqgL9QFWX5LJcI6kw6Gf2xBJmTyzJd1GOOY7jHa1PLB3ZlouIpFoZIU6rtfseGTNUOW+HqupqYHW/vG9kjF+S6zIYY4wZPLtpvTHGmCwWGIwxxmSxwGCMMSaLBQZjjDFZLDAYY4zJYoHBGGNMFgsMxhhjsuT0l8+5IiINwHCf2VANNI5gcY4143n/bd/Hr/G8/5n7foKqHvEpP8dkYDgaIrJmMD8JP16N5/23fR+f+w7je/+Hs+/WlWSMMSaLBQZjjDFZxmNgeCjfBciz8bz/tu/j13je/yHv+7g7x2CMMebwxmOLwRhjzGFYYDDGGJNlXAUGEVksIltEZLuI3JPv8owmEdklIutFZK2IjI3H3+WQiPxYRA6IyLsZeZUi8p8isi01rMhnGXPlEPu+XET2pD7/tSJyeT7LmCsiMk1EXhKRjSKyQUT+KpU/Xj77Q+3/kD7/cXOOQUR8eI8Z/SRQj/eY0etUdWNeCzZKRGQXsFBVx8WPfETk40An8FNVPTWV9/dAs6p+J3VgUKGqy/JZzlw4xL4vBzpV9bv5LFuuichkYLKq/kFESoC3gCuBmxgfn/2h9v8ahvD5j6cWwznAdlXdoaoxYCVwRZ7LZHJEVV8BmvtlXwE8lhp/DO8f5rhziH0fF1T1Q1X9Q2q8A9gETGX8fPaH2v8hGU+BYSqwO2O6nmG8YccwBX4jIm+JyG35LkyeTFTVD1Pj+4CJ+SxMHtwlIu+kupqOy66UTCIyAzgD+D3j8LPvt/8whM9/PAWG8e5jqnomcBlwZ6q7YdxSrw91fPSjen4AnAgsAD4E/m9eS5NjIlIM/AvwJVVtz5w3Hj77AfZ/SJ//eAoMe4BpGdO1qbxxQVX3pIYHgH/D61obb/an+mB7+2IP5Lk8o0ZV96tqUlVd4GGO489fRAJ4leLjqvqvqexx89kPtP9D/fzHU2B4E5gtIjNFJAgsBVbluUyjQkSKUieiEJEi4FPAu4df67i0CrgxNX4j8GweyzKqeivFlD/mOP38RUSAFcAmVb0/Y9a4+OwPtf9D/fzHzVVJAKlLtP4J8AE/VtW/y2+JRoeIzMJrJQD4gSeO930XkV8AF+Ddcng/8E3gGeCXwHS827Zfo6rH3UnaQ+z7BXjdCArsAm7P6HM/bojIx4BXgfWAm8r+f/D62cfDZ3+o/b+OIXz+4yowGGOMObLx1JVkjDFmECwwGGOMyWKBwRhjTBYLDMYYY7JYYDDGGJPFAoMxo0xELhCR5/JdDmMOxQKDMcaYLBYYjDkEEfm8iLyRun/9j0TEJyKdIvKPqXvdvyAiNallF4jI71I3Kfu33puUiUidiPyXiKwTkT+IyImpzReLyNMisllEHk/9YtWYMcECgzEDEJGTgWuBj6rqAiAJfA4oAtao6jzgt3i/Kgb4KbBMVU/H+9Vpb/7jwIOqOh/4CN4NzMC76+WXgFOAWcBHc7xLxgyaP98FMGaMuhg4C3gzdTBfgHfjNRd4MrXMz4F/FZEyoFxVf5vKfwx4KnV/qqmq+m8AqhoBSG3vDVWtT02vBWYA/53zvTJmECwwGDMwAR5T1a9lZYr8737LDfeeMtGM8ST2v2jGEOtKMmZgLwBXi8gESD8z+AS8/5mrU8tcD/y3qrYBLSJyfir/BuC3qSdo1YvIlalthESkcDR3wpjhsKMUYwagqhtF5Ot4T71zgDhwJ9AFnJOadwDvPAR4t3L+Yari3wH8WSr/BuBHInJvahufHcXdMGZY7O6qxgyBiHSqanG+y2FMLllXkjHGmCzWYjDGGJPFWgzGGGOyWGAwxhiTxQKDMcaYLBYYjDHGZLHAYIwxJsv/D7XUGwqtgaO2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_sizes = []\n",
    "for exp, result in zip([lr_default, lr_low, lr_high], [\".01_\", \".0001_\", \".75_\"]):\n",
    "  df = pd.DataFrame.from_dict(exp.history)\n",
    "  df['epoch'] = df.index.values\n",
    "  df['Learning Rate'] = result\n",
    "  batch_sizes.append(df)\n",
    "df = pd.concat(batch_sizes)\n",
    "df['Learning Rate'] = df['Learning Rate'].astype('str')\n",
    "df.head()\n",
    "sns.lineplot(x='epoch', y='val_loss', hue='Learning Rate', data=df);\n",
    "sns.lineplot(x='epoch', y='val_accuracy', hue='Learning Rate', data=df);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08780ad6",
   "metadata": {},
   "source": [
    "#### Please refer to module 2 of NeuralNetworksAndDeepLearning - ModelPerformanceAndFit for tasks 8-12\n",
    "#### Task 8\n",
    "##### Initialize the sequential neural network model with 32 neurons for the 1st hidden layer, 32 neurons for the second layer, and appropriate input and output layers, name the model `model`. Keep the learning rate at 0.0001\n",
    "##### Compile the model using the \"adam\" optimizer, \"binary_crossentropy\" loss, and using \"accuracy\" as a metric.\n",
    "##### Print the summary of the model using the command `create_model().summary()`\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed5a198a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 32)                1696      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2785 (10.88 KB)\n",
      "Trainable params: 2785 (10.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(lr=.0001):\n",
    "  opt = Adam(learning_rate=lr)\n",
    "  model = Sequential([\n",
    "          Dense(32, activation='relu', input_dim=52),\n",
    "          Dense(32, activation='relu'),\n",
    "          Dense(1, activation='sigmoid')\n",
    "  ])\n",
    "  model.compile(optimizer=opt, loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "  return model\n",
    "create_model().summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0148d964",
   "metadata": {},
   "source": [
    "#### Task 9\n",
    "##### Fit the model using train and validation sets with 25 epochs, default batch size, and assign it to `bt_default`, `bt_small` and `bt_large` variables for batch size `32`, `8` and `512` respectively.\n",
    "#### Result:\n",
    "##### Default\n",
    "- Batch size is 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bbd3737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "901/901 [==============================] - 1s 595us/step - loss: 0.3638 - accuracy: 0.8846 - val_loss: 0.3174 - val_accuracy: 0.8846\n",
      "Epoch 2/25\n",
      "901/901 [==============================] - 0s 512us/step - loss: 0.3014 - accuracy: 0.8889 - val_loss: 0.2970 - val_accuracy: 0.8875\n",
      "Epoch 3/25\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.2862 - accuracy: 0.8943 - val_loss: 0.2864 - val_accuracy: 0.8904\n",
      "Epoch 4/25\n",
      "901/901 [==============================] - 0s 498us/step - loss: 0.2779 - accuracy: 0.8972 - val_loss: 0.2795 - val_accuracy: 0.8901\n",
      "Epoch 5/25\n",
      "901/901 [==============================] - 0s 495us/step - loss: 0.2716 - accuracy: 0.8987 - val_loss: 0.2737 - val_accuracy: 0.8924\n",
      "Epoch 6/25\n",
      "901/901 [==============================] - 0s 520us/step - loss: 0.2655 - accuracy: 0.8991 - val_loss: 0.2678 - val_accuracy: 0.8946\n",
      "Epoch 7/25\n",
      "901/901 [==============================] - 1s 578us/step - loss: 0.2591 - accuracy: 0.9015 - val_loss: 0.2612 - val_accuracy: 0.8974\n",
      "Epoch 8/25\n",
      "901/901 [==============================] - 0s 498us/step - loss: 0.2518 - accuracy: 0.9026 - val_loss: 0.2539 - val_accuracy: 0.8987\n",
      "Epoch 9/25\n",
      "901/901 [==============================] - 0s 496us/step - loss: 0.2441 - accuracy: 0.9039 - val_loss: 0.2459 - val_accuracy: 0.8995\n",
      "Epoch 10/25\n",
      "901/901 [==============================] - 0s 482us/step - loss: 0.2363 - accuracy: 0.9054 - val_loss: 0.2385 - val_accuracy: 0.9010\n",
      "Epoch 11/25\n",
      "901/901 [==============================] - 0s 537us/step - loss: 0.2290 - accuracy: 0.9065 - val_loss: 0.2320 - val_accuracy: 0.9047\n",
      "Epoch 12/25\n",
      "901/901 [==============================] - 0s 501us/step - loss: 0.2226 - accuracy: 0.9073 - val_loss: 0.2260 - val_accuracy: 0.9050\n",
      "Epoch 13/25\n",
      "901/901 [==============================] - 0s 549us/step - loss: 0.2171 - accuracy: 0.9081 - val_loss: 0.2218 - val_accuracy: 0.9053\n",
      "Epoch 14/25\n",
      "901/901 [==============================] - 0s 546us/step - loss: 0.2125 - accuracy: 0.9091 - val_loss: 0.2173 - val_accuracy: 0.9060\n",
      "Epoch 15/25\n",
      "901/901 [==============================] - 1s 603us/step - loss: 0.2090 - accuracy: 0.9095 - val_loss: 0.2142 - val_accuracy: 0.9073\n",
      "Epoch 16/25\n",
      "901/901 [==============================] - 1s 561us/step - loss: 0.2063 - accuracy: 0.9108 - val_loss: 0.2121 - val_accuracy: 0.9074\n",
      "Epoch 17/25\n",
      "901/901 [==============================] - 0s 504us/step - loss: 0.2041 - accuracy: 0.9113 - val_loss: 0.2108 - val_accuracy: 0.9071\n",
      "Epoch 18/25\n",
      "901/901 [==============================] - 0s 500us/step - loss: 0.2022 - accuracy: 0.9115 - val_loss: 0.2097 - val_accuracy: 0.9081\n",
      "Epoch 19/25\n",
      "901/901 [==============================] - 0s 514us/step - loss: 0.2008 - accuracy: 0.9123 - val_loss: 0.2092 - val_accuracy: 0.9073\n",
      "Epoch 20/25\n",
      "901/901 [==============================] - 0s 501us/step - loss: 0.1996 - accuracy: 0.9119 - val_loss: 0.2075 - val_accuracy: 0.9082\n",
      "Epoch 21/25\n",
      "901/901 [==============================] - 0s 498us/step - loss: 0.1983 - accuracy: 0.9123 - val_loss: 0.2067 - val_accuracy: 0.9092\n",
      "Epoch 22/25\n",
      "901/901 [==============================] - 0s 497us/step - loss: 0.1974 - accuracy: 0.9125 - val_loss: 0.2060 - val_accuracy: 0.9081\n",
      "Epoch 23/25\n",
      "901/901 [==============================] - 0s 493us/step - loss: 0.1964 - accuracy: 0.9125 - val_loss: 0.2058 - val_accuracy: 0.9102\n",
      "Epoch 24/25\n",
      "901/901 [==============================] - 0s 492us/step - loss: 0.1958 - accuracy: 0.9129 - val_loss: 0.2051 - val_accuracy: 0.9074\n",
      "Epoch 25/25\n",
      "901/901 [==============================] - 0s 499us/step - loss: 0.1948 - accuracy: 0.9128 - val_loss: 0.2046 - val_accuracy: 0.9076\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "bt_default = model.fit(X_train_scaled_ex, y_train_ex,\n",
    "                                epochs=25,\n",
    "                                batch_size=32,\n",
    "                                validation_data=(X_val_scaled_ex, y_val_ex))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0bc6c1",
   "metadata": {},
   "source": [
    "##### Small batch size\n",
    "- Batch size is 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74546cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3604/3604 [==============================] - 2s 499us/step - loss: 0.3275 - accuracy: 0.8849 - val_loss: 0.2931 - val_accuracy: 0.8877\n",
      "Epoch 2/25\n",
      "3604/3604 [==============================] - 2s 504us/step - loss: 0.2809 - accuracy: 0.8962 - val_loss: 0.2783 - val_accuracy: 0.8904\n",
      "Epoch 3/25\n",
      "3604/3604 [==============================] - 2s 572us/step - loss: 0.2684 - accuracy: 0.8985 - val_loss: 0.2673 - val_accuracy: 0.8933\n",
      "Epoch 4/25\n",
      "3604/3604 [==============================] - 2s 491us/step - loss: 0.2559 - accuracy: 0.9003 - val_loss: 0.2551 - val_accuracy: 0.8950\n",
      "Epoch 5/25\n",
      "3604/3604 [==============================] - 2s 505us/step - loss: 0.2421 - accuracy: 0.9024 - val_loss: 0.2396 - val_accuracy: 0.8976\n",
      "Epoch 6/25\n",
      "3604/3604 [==============================] - 2s 481us/step - loss: 0.2277 - accuracy: 0.9048 - val_loss: 0.2263 - val_accuracy: 0.9021\n",
      "Epoch 7/25\n",
      "3604/3604 [==============================] - 2s 481us/step - loss: 0.2165 - accuracy: 0.9074 - val_loss: 0.2172 - val_accuracy: 0.9044\n",
      "Epoch 8/25\n",
      "3604/3604 [==============================] - 2s 484us/step - loss: 0.2088 - accuracy: 0.9094 - val_loss: 0.2130 - val_accuracy: 0.9052\n",
      "Epoch 9/25\n",
      "3604/3604 [==============================] - 2s 486us/step - loss: 0.2040 - accuracy: 0.9105 - val_loss: 0.2083 - val_accuracy: 0.9056\n",
      "Epoch 10/25\n",
      "3604/3604 [==============================] - 2s 500us/step - loss: 0.2007 - accuracy: 0.9116 - val_loss: 0.2063 - val_accuracy: 0.9073\n",
      "Epoch 11/25\n",
      "3604/3604 [==============================] - 2s 485us/step - loss: 0.1979 - accuracy: 0.9127 - val_loss: 0.2053 - val_accuracy: 0.9084\n",
      "Epoch 12/25\n",
      "3604/3604 [==============================] - 2s 600us/step - loss: 0.1960 - accuracy: 0.9124 - val_loss: 0.2028 - val_accuracy: 0.9079\n",
      "Epoch 13/25\n",
      "3604/3604 [==============================] - 2s 542us/step - loss: 0.1940 - accuracy: 0.9125 - val_loss: 0.2010 - val_accuracy: 0.9079\n",
      "Epoch 14/25\n",
      "3604/3604 [==============================] - 2s 479us/step - loss: 0.1920 - accuracy: 0.9129 - val_loss: 0.1997 - val_accuracy: 0.9081\n",
      "Epoch 15/25\n",
      "3604/3604 [==============================] - 2s 508us/step - loss: 0.1904 - accuracy: 0.9139 - val_loss: 0.1984 - val_accuracy: 0.9090\n",
      "Epoch 16/25\n",
      "3604/3604 [==============================] - 2s 584us/step - loss: 0.1887 - accuracy: 0.9142 - val_loss: 0.1977 - val_accuracy: 0.9097\n",
      "Epoch 17/25\n",
      "3604/3604 [==============================] - 2s 569us/step - loss: 0.1875 - accuracy: 0.9145 - val_loss: 0.1967 - val_accuracy: 0.9099\n",
      "Epoch 18/25\n",
      "3604/3604 [==============================] - 2s 572us/step - loss: 0.1862 - accuracy: 0.9145 - val_loss: 0.1956 - val_accuracy: 0.9099\n",
      "Epoch 19/25\n",
      "3604/3604 [==============================] - 2s 535us/step - loss: 0.1847 - accuracy: 0.9148 - val_loss: 0.1952 - val_accuracy: 0.9081\n",
      "Epoch 20/25\n",
      "3604/3604 [==============================] - 2s 610us/step - loss: 0.1837 - accuracy: 0.9148 - val_loss: 0.1944 - val_accuracy: 0.9084\n",
      "Epoch 21/25\n",
      "3604/3604 [==============================] - 2s 529us/step - loss: 0.1825 - accuracy: 0.9155 - val_loss: 0.1941 - val_accuracy: 0.9065\n",
      "Epoch 22/25\n",
      "3604/3604 [==============================] - 2s 528us/step - loss: 0.1817 - accuracy: 0.9155 - val_loss: 0.1935 - val_accuracy: 0.9099\n",
      "Epoch 23/25\n",
      "3604/3604 [==============================] - 2s 493us/step - loss: 0.1808 - accuracy: 0.9158 - val_loss: 0.1921 - val_accuracy: 0.9074\n",
      "Epoch 24/25\n",
      "3604/3604 [==============================] - 2s 500us/step - loss: 0.1796 - accuracy: 0.9161 - val_loss: 0.1962 - val_accuracy: 0.9082\n",
      "Epoch 25/25\n",
      "3604/3604 [==============================] - 2s 519us/step - loss: 0.1791 - accuracy: 0.9163 - val_loss: 0.1919 - val_accuracy: 0.9079\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "bt_small = model.fit(X_train_scaled_ex, y_train_ex,\n",
    "                                epochs=25,\n",
    "                                batch_size=8,\n",
    "                                validation_data=(X_val_scaled_ex, y_val_ex))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3dce1c",
   "metadata": {},
   "source": [
    "##### Large batch size\n",
    "- Batch Size is 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1fe425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7815 - accuracy: 0.2583 - val_loss: 0.7244 - val_accuracy: 0.4075\n",
      "Epoch 2/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.5681 - val_loss: 0.6260 - val_accuracy: 0.7184\n",
      "Epoch 3/25\n",
      "57/57 [==============================] - 0s 942us/step - loss: 0.5797 - accuracy: 0.8084 - val_loss: 0.5356 - val_accuracy: 0.8597\n",
      "Epoch 4/25\n",
      "57/57 [==============================] - 0s 964us/step - loss: 0.4925 - accuracy: 0.8782 - val_loss: 0.4517 - val_accuracy: 0.8827\n",
      "Epoch 5/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8874 - val_loss: 0.3860 - val_accuracy: 0.8848\n",
      "Epoch 6/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8881 - val_loss: 0.3488 - val_accuracy: 0.8848\n",
      "Epoch 7/25\n",
      "57/57 [==============================] - 0s 981us/step - loss: 0.3370 - accuracy: 0.8881 - val_loss: 0.3311 - val_accuracy: 0.8846\n",
      "Epoch 8/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3243 - accuracy: 0.8881 - val_loss: 0.3225 - val_accuracy: 0.8846\n",
      "Epoch 9/25\n",
      "57/57 [==============================] - 0s 974us/step - loss: 0.3176 - accuracy: 0.8881 - val_loss: 0.3175 - val_accuracy: 0.8846\n",
      "Epoch 10/25\n",
      "57/57 [==============================] - 0s 986us/step - loss: 0.3133 - accuracy: 0.8880 - val_loss: 0.3137 - val_accuracy: 0.8848\n",
      "Epoch 11/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8881 - val_loss: 0.3105 - val_accuracy: 0.8848\n",
      "Epoch 12/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3066 - accuracy: 0.8881 - val_loss: 0.3075 - val_accuracy: 0.8846\n",
      "Epoch 13/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3036 - accuracy: 0.8882 - val_loss: 0.3048 - val_accuracy: 0.8843\n",
      "Epoch 14/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3009 - accuracy: 0.8881 - val_loss: 0.3022 - val_accuracy: 0.8836\n",
      "Epoch 15/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.2982 - accuracy: 0.8885 - val_loss: 0.2997 - val_accuracy: 0.8835\n",
      "Epoch 16/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.2957 - accuracy: 0.8886 - val_loss: 0.2974 - val_accuracy: 0.8835\n",
      "Epoch 17/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.2934 - accuracy: 0.8888 - val_loss: 0.2951 - val_accuracy: 0.8838\n",
      "Epoch 18/25\n",
      "57/57 [==============================] - 0s 998us/step - loss: 0.2913 - accuracy: 0.8894 - val_loss: 0.2932 - val_accuracy: 0.8849\n",
      "Epoch 19/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.2893 - accuracy: 0.8899 - val_loss: 0.2912 - val_accuracy: 0.8859\n",
      "Epoch 20/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8909 - val_loss: 0.2894 - val_accuracy: 0.8861\n",
      "Epoch 21/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.2856 - accuracy: 0.8912 - val_loss: 0.2878 - val_accuracy: 0.8867\n",
      "Epoch 22/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.2840 - accuracy: 0.8917 - val_loss: 0.2863 - val_accuracy: 0.8882\n",
      "Epoch 23/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.2825 - accuracy: 0.8929 - val_loss: 0.2850 - val_accuracy: 0.8896\n",
      "Epoch 24/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.2811 - accuracy: 0.8933 - val_loss: 0.2837 - val_accuracy: 0.8898\n",
      "Epoch 25/25\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.2798 - accuracy: 0.8939 - val_loss: 0.2824 - val_accuracy: 0.8908\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "bt_large = model.fit(X_train_scaled_ex, y_train_ex,\n",
    "                                epochs=25,\n",
    "                                batch_size=512,\n",
    "                                validation_data=(X_val_scaled_ex, y_val_ex))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28304b2c",
   "metadata": {},
   "source": [
    "#### Task 10\n",
    "##### Create a dataframe with the loss and accuracy for training and validation data along with their epoch and batch size.\n",
    "##### Plot the validation accuracy and loss curves for the models with different batch size to analyze and compare the results.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f649852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.36377790570259094,\n",
       "  0.301350861787796,\n",
       "  0.2862134873867035,\n",
       "  0.2779248356819153,\n",
       "  0.271584153175354,\n",
       "  0.26545485854148865,\n",
       "  0.2590863108634949,\n",
       "  0.25180235505104065,\n",
       "  0.2440667450428009,\n",
       "  0.23631638288497925,\n",
       "  0.22903047502040863,\n",
       "  0.22256408631801605,\n",
       "  0.21714293956756592,\n",
       "  0.21247389912605286,\n",
       "  0.20899493992328644,\n",
       "  0.20629440248012543,\n",
       "  0.20407827198505402,\n",
       "  0.20218291878700256,\n",
       "  0.20084349811077118,\n",
       "  0.19964464008808136,\n",
       "  0.1983422338962555,\n",
       "  0.19736771285533905,\n",
       "  0.1963953822851181,\n",
       "  0.19577111303806305,\n",
       "  0.19476912915706635],\n",
       " 'accuracy': [0.8846380710601807,\n",
       "  0.8888696432113647,\n",
       "  0.8943498134613037,\n",
       "  0.897193968296051,\n",
       "  0.8987201452255249,\n",
       "  0.8991363644599915,\n",
       "  0.9014602303504944,\n",
       "  0.9026395082473755,\n",
       "  0.9038881659507751,\n",
       "  0.9054489731788635,\n",
       "  0.906454861164093,\n",
       "  0.9072872996330261,\n",
       "  0.9080850481987,\n",
       "  0.909125566482544,\n",
       "  0.9095417857170105,\n",
       "  0.9107904434204102,\n",
       "  0.9113107323646545,\n",
       "  0.9114841818809509,\n",
       "  0.9122819304466248,\n",
       "  0.9119350910186768,\n",
       "  0.912316620349884,\n",
       "  0.9124900102615356,\n",
       "  0.9124900102615356,\n",
       "  0.9128715395927429,\n",
       "  0.9128368496894836],\n",
       " 'val_loss': [0.3174273669719696,\n",
       "  0.2969977855682373,\n",
       "  0.2863925099372864,\n",
       "  0.27954140305519104,\n",
       "  0.2737140655517578,\n",
       "  0.267778217792511,\n",
       "  0.2611604332923889,\n",
       "  0.25394535064697266,\n",
       "  0.24585646390914917,\n",
       "  0.2384888082742691,\n",
       "  0.23200367391109467,\n",
       "  0.2259930819272995,\n",
       "  0.22177988290786743,\n",
       "  0.2172536700963974,\n",
       "  0.21421803534030914,\n",
       "  0.2121492326259613,\n",
       "  0.210770845413208,\n",
       "  0.2097119390964508,\n",
       "  0.2092088758945465,\n",
       "  0.20746810734272003,\n",
       "  0.20673488080501556,\n",
       "  0.2060476541519165,\n",
       "  0.20581604540348053,\n",
       "  0.20509570837020874,\n",
       "  0.20455299317836761],\n",
       " 'val_accuracy': [0.8846091628074646,\n",
       "  0.887522280216217,\n",
       "  0.8904353380203247,\n",
       "  0.8901116847991943,\n",
       "  0.8923774361610413,\n",
       "  0.8946431279182434,\n",
       "  0.8973944187164307,\n",
       "  0.8986890912055969,\n",
       "  0.8994982838630676,\n",
       "  0.9009548425674438,\n",
       "  0.904677152633667,\n",
       "  0.9050008058547974,\n",
       "  0.9053244590759277,\n",
       "  0.9059718251228333,\n",
       "  0.9072665572166443,\n",
       "  0.9074283838272095,\n",
       "  0.9071047306060791,\n",
       "  0.908075749874115,\n",
       "  0.9072665572166443,\n",
       "  0.9082375764846802,\n",
       "  0.9092085957527161,\n",
       "  0.908075749874115,\n",
       "  0.910179615020752,\n",
       "  0.9074283838272095,\n",
       "  0.9075902104377747]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt_default.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01e36e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = []\n",
    "for exp, result in zip([bt_default, bt_small, bt_large], [\"32\", \"8\", \"512\"]):\n",
    "  df = pd.DataFrame.from_dict(exp.history)\n",
    "  df['epoch'] = df.index.values\n",
    "  df['Batch Size'] = result\n",
    "  batch_sizes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d69a8102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>epoch</th>\n",
       "      <th>Batch Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.781522</td>\n",
       "      <td>0.258264</td>\n",
       "      <td>0.724433</td>\n",
       "      <td>0.407509</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.673519</td>\n",
       "      <td>0.568069</td>\n",
       "      <td>0.625987</td>\n",
       "      <td>0.718401</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.579651</td>\n",
       "      <td>0.808366</td>\n",
       "      <td>0.535620</td>\n",
       "      <td>0.859686</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.492481</td>\n",
       "      <td>0.878221</td>\n",
       "      <td>0.451651</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.415850</td>\n",
       "      <td>0.887413</td>\n",
       "      <td>0.386024</td>\n",
       "      <td>0.884771</td>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.363950</td>\n",
       "      <td>0.888072</td>\n",
       "      <td>0.348839</td>\n",
       "      <td>0.884771</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.336970</td>\n",
       "      <td>0.888072</td>\n",
       "      <td>0.331088</td>\n",
       "      <td>0.884609</td>\n",
       "      <td>6</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.324271</td>\n",
       "      <td>0.888072</td>\n",
       "      <td>0.322492</td>\n",
       "      <td>0.884609</td>\n",
       "      <td>7</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.317624</td>\n",
       "      <td>0.888072</td>\n",
       "      <td>0.317539</td>\n",
       "      <td>0.884609</td>\n",
       "      <td>8</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.313293</td>\n",
       "      <td>0.888037</td>\n",
       "      <td>0.313744</td>\n",
       "      <td>0.884771</td>\n",
       "      <td>9</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.309748</td>\n",
       "      <td>0.888072</td>\n",
       "      <td>0.310499</td>\n",
       "      <td>0.884771</td>\n",
       "      <td>10</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.306567</td>\n",
       "      <td>0.888107</td>\n",
       "      <td>0.307544</td>\n",
       "      <td>0.884609</td>\n",
       "      <td>11</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.888211</td>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.884286</td>\n",
       "      <td>12</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.300869</td>\n",
       "      <td>0.888141</td>\n",
       "      <td>0.302194</td>\n",
       "      <td>0.883638</td>\n",
       "      <td>13</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.298232</td>\n",
       "      <td>0.888453</td>\n",
       "      <td>0.299698</td>\n",
       "      <td>0.883476</td>\n",
       "      <td>14</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.295748</td>\n",
       "      <td>0.888592</td>\n",
       "      <td>0.297382</td>\n",
       "      <td>0.883476</td>\n",
       "      <td>15</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.293441</td>\n",
       "      <td>0.888766</td>\n",
       "      <td>0.295136</td>\n",
       "      <td>0.883800</td>\n",
       "      <td>16</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.291297</td>\n",
       "      <td>0.889425</td>\n",
       "      <td>0.293176</td>\n",
       "      <td>0.884933</td>\n",
       "      <td>17</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.289311</td>\n",
       "      <td>0.889875</td>\n",
       "      <td>0.291203</td>\n",
       "      <td>0.885904</td>\n",
       "      <td>18</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.287400</td>\n",
       "      <td>0.890916</td>\n",
       "      <td>0.289435</td>\n",
       "      <td>0.886066</td>\n",
       "      <td>19</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.285643</td>\n",
       "      <td>0.891228</td>\n",
       "      <td>0.287812</td>\n",
       "      <td>0.886713</td>\n",
       "      <td>20</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.284018</td>\n",
       "      <td>0.891714</td>\n",
       "      <td>0.286329</td>\n",
       "      <td>0.888170</td>\n",
       "      <td>21</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.282513</td>\n",
       "      <td>0.892858</td>\n",
       "      <td>0.284955</td>\n",
       "      <td>0.889626</td>\n",
       "      <td>22</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.281107</td>\n",
       "      <td>0.893344</td>\n",
       "      <td>0.283690</td>\n",
       "      <td>0.889788</td>\n",
       "      <td>23</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.279778</td>\n",
       "      <td>0.893899</td>\n",
       "      <td>0.282450</td>\n",
       "      <td>0.890759</td>\n",
       "      <td>24</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy  epoch Batch Size\n",
       "0   0.781522  0.258264  0.724433      0.407509      0        512\n",
       "1   0.673519  0.568069  0.625987      0.718401      1        512\n",
       "2   0.579651  0.808366  0.535620      0.859686      2        512\n",
       "3   0.492481  0.878221  0.451651      0.882667      3        512\n",
       "4   0.415850  0.887413  0.386024      0.884771      4        512\n",
       "5   0.363950  0.888072  0.348839      0.884771      5        512\n",
       "6   0.336970  0.888072  0.331088      0.884609      6        512\n",
       "7   0.324271  0.888072  0.322492      0.884609      7        512\n",
       "8   0.317624  0.888072  0.317539      0.884609      8        512\n",
       "9   0.313293  0.888037  0.313744      0.884771      9        512\n",
       "10  0.309748  0.888072  0.310499      0.884771     10        512\n",
       "11  0.306567  0.888107  0.307544      0.884609     11        512\n",
       "12  0.303635  0.888211  0.304800      0.884286     12        512\n",
       "13  0.300869  0.888141  0.302194      0.883638     13        512\n",
       "14  0.298232  0.888453  0.299698      0.883476     14        512\n",
       "15  0.295748  0.888592  0.297382      0.883476     15        512\n",
       "16  0.293441  0.888766  0.295136      0.883800     16        512\n",
       "17  0.291297  0.889425  0.293176      0.884933     17        512\n",
       "18  0.289311  0.889875  0.291203      0.885904     18        512\n",
       "19  0.287400  0.890916  0.289435      0.886066     19        512\n",
       "20  0.285643  0.891228  0.287812      0.886713     20        512\n",
       "21  0.284018  0.891714  0.286329      0.888170     21        512\n",
       "22  0.282513  0.892858  0.284955      0.889626     22        512\n",
       "23  0.281107  0.893344  0.283690      0.889788     23        512\n",
       "24  0.279778  0.893899  0.282450      0.890759     24        512"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45d202a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_sizes = []\n",
    "for exp, result in zip([bt_default, bt_small, bt_large], [\"32\", \"8\", \"512\"]):\n",
    "  df = pd.DataFrame.from_dict(exp.history)\n",
    "  df['epoch'] = df.index.values\n",
    "  df['Batch Size'] = result\n",
    "  batch_sizes.append(df)\n",
    "df = pd.concat(batch_sizes)\n",
    "df['Batch Size'] = df['Batch Size'].astype('str')\n",
    "df.head()\n",
    "sns.lineplot(x='epoch', y='val_accuracy', hue='Batch Size', data=df);\n",
    "sns.lineplot(x='epoch', y='val_loss', hue='Batch Size', data=df);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550fb8e7",
   "metadata": {},
   "source": [
    "#### Task 11\n",
    "##### Fit the model using train and validation sets with default batch size, learning rate and assign it to `epochs_medium`, `epochs_low` and `epochs_high` variables for number of epochs `100`, `50` and `200` respectively.\n",
    "#### Result:\n",
    "##### Medium\n",
    "- Number of epochs are 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bbc682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "901/901 [==============================] - 1s 581us/step - loss: 0.3558 - accuracy: 0.8877 - val_loss: 0.3090 - val_accuracy: 0.8846\n",
      "Epoch 2/100\n",
      "901/901 [==============================] - 0s 515us/step - loss: 0.2977 - accuracy: 0.8889 - val_loss: 0.2917 - val_accuracy: 0.8880\n",
      "Epoch 3/100\n",
      "901/901 [==============================] - 0s 534us/step - loss: 0.2856 - accuracy: 0.8949 - val_loss: 0.2831 - val_accuracy: 0.8911\n",
      "Epoch 4/100\n",
      "901/901 [==============================] - 0s 516us/step - loss: 0.2785 - accuracy: 0.8977 - val_loss: 0.2776 - val_accuracy: 0.8925\n",
      "Epoch 5/100\n",
      "901/901 [==============================] - 0s 546us/step - loss: 0.2725 - accuracy: 0.8989 - val_loss: 0.2717 - val_accuracy: 0.8943\n",
      "Epoch 6/100\n",
      "901/901 [==============================] - 0s 523us/step - loss: 0.2664 - accuracy: 0.8993 - val_loss: 0.2654 - val_accuracy: 0.8961\n",
      "Epoch 7/100\n",
      "901/901 [==============================] - 1s 562us/step - loss: 0.2599 - accuracy: 0.9002 - val_loss: 0.2587 - val_accuracy: 0.8964\n",
      "Epoch 8/100\n",
      "901/901 [==============================] - 0s 512us/step - loss: 0.2526 - accuracy: 0.9013 - val_loss: 0.2513 - val_accuracy: 0.8979\n",
      "Epoch 9/100\n",
      "901/901 [==============================] - 0s 504us/step - loss: 0.2446 - accuracy: 0.9026 - val_loss: 0.2436 - val_accuracy: 0.8997\n",
      "Epoch 10/100\n",
      "901/901 [==============================] - 0s 497us/step - loss: 0.2365 - accuracy: 0.9040 - val_loss: 0.2361 - val_accuracy: 0.9016\n",
      "Epoch 11/100\n",
      "901/901 [==============================] - 0s 506us/step - loss: 0.2288 - accuracy: 0.9049 - val_loss: 0.2286 - val_accuracy: 0.9029\n",
      "Epoch 12/100\n",
      "901/901 [==============================] - 1s 568us/step - loss: 0.2220 - accuracy: 0.9063 - val_loss: 0.2224 - val_accuracy: 0.9045\n",
      "Epoch 13/100\n",
      "901/901 [==============================] - 1s 605us/step - loss: 0.2163 - accuracy: 0.9079 - val_loss: 0.2173 - val_accuracy: 0.9071\n",
      "Epoch 14/100\n",
      "901/901 [==============================] - 0s 531us/step - loss: 0.2116 - accuracy: 0.9087 - val_loss: 0.2136 - val_accuracy: 0.9082\n",
      "Epoch 15/100\n",
      "901/901 [==============================] - 1s 556us/step - loss: 0.2080 - accuracy: 0.9096 - val_loss: 0.2120 - val_accuracy: 0.9086\n",
      "Epoch 16/100\n",
      "901/901 [==============================] - 0s 514us/step - loss: 0.2051 - accuracy: 0.9093 - val_loss: 0.2084 - val_accuracy: 0.9089\n",
      "Epoch 17/100\n",
      "901/901 [==============================] - 0s 504us/step - loss: 0.2029 - accuracy: 0.9095 - val_loss: 0.2076 - val_accuracy: 0.9099\n",
      "Epoch 18/100\n",
      "901/901 [==============================] - 0s 507us/step - loss: 0.2011 - accuracy: 0.9112 - val_loss: 0.2056 - val_accuracy: 0.9100\n",
      "Epoch 19/100\n",
      "901/901 [==============================] - 0s 550us/step - loss: 0.1997 - accuracy: 0.9113 - val_loss: 0.2046 - val_accuracy: 0.9094\n",
      "Epoch 20/100\n",
      "901/901 [==============================] - 0s 508us/step - loss: 0.1982 - accuracy: 0.9115 - val_loss: 0.2035 - val_accuracy: 0.9095\n",
      "Epoch 21/100\n",
      "901/901 [==============================] - 1s 560us/step - loss: 0.1970 - accuracy: 0.9122 - val_loss: 0.2026 - val_accuracy: 0.9092\n",
      "Epoch 22/100\n",
      "901/901 [==============================] - 0s 509us/step - loss: 0.1958 - accuracy: 0.9124 - val_loss: 0.2021 - val_accuracy: 0.9090\n",
      "Epoch 23/100\n",
      "901/901 [==============================] - 0s 523us/step - loss: 0.1949 - accuracy: 0.9125 - val_loss: 0.2014 - val_accuracy: 0.9079\n",
      "Epoch 24/100\n",
      "901/901 [==============================] - 1s 569us/step - loss: 0.1939 - accuracy: 0.9128 - val_loss: 0.2021 - val_accuracy: 0.9082\n",
      "Epoch 25/100\n",
      "901/901 [==============================] - 1s 555us/step - loss: 0.1928 - accuracy: 0.9126 - val_loss: 0.2016 - val_accuracy: 0.9105\n",
      "Epoch 26/100\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.1921 - accuracy: 0.9125 - val_loss: 0.1994 - val_accuracy: 0.9094\n",
      "Epoch 27/100\n",
      "901/901 [==============================] - 0s 494us/step - loss: 0.1911 - accuracy: 0.9134 - val_loss: 0.1988 - val_accuracy: 0.9092\n",
      "Epoch 28/100\n",
      "901/901 [==============================] - 0s 500us/step - loss: 0.1905 - accuracy: 0.9131 - val_loss: 0.1982 - val_accuracy: 0.9102\n",
      "Epoch 29/100\n",
      "901/901 [==============================] - 0s 497us/step - loss: 0.1896 - accuracy: 0.9134 - val_loss: 0.1975 - val_accuracy: 0.9102\n",
      "Epoch 30/100\n",
      "901/901 [==============================] - 0s 493us/step - loss: 0.1888 - accuracy: 0.9136 - val_loss: 0.1968 - val_accuracy: 0.9095\n",
      "Epoch 31/100\n",
      "901/901 [==============================] - 0s 495us/step - loss: 0.1879 - accuracy: 0.9136 - val_loss: 0.1964 - val_accuracy: 0.9108\n",
      "Epoch 32/100\n",
      "901/901 [==============================] - 0s 496us/step - loss: 0.1872 - accuracy: 0.9143 - val_loss: 0.1958 - val_accuracy: 0.9100\n",
      "Epoch 33/100\n",
      "901/901 [==============================] - 0s 497us/step - loss: 0.1866 - accuracy: 0.9136 - val_loss: 0.1953 - val_accuracy: 0.9107\n",
      "Epoch 34/100\n",
      "901/901 [==============================] - 0s 497us/step - loss: 0.1859 - accuracy: 0.9148 - val_loss: 0.1946 - val_accuracy: 0.9102\n",
      "Epoch 35/100\n",
      "901/901 [==============================] - 0s 495us/step - loss: 0.1853 - accuracy: 0.9146 - val_loss: 0.1945 - val_accuracy: 0.9105\n",
      "Epoch 36/100\n",
      "901/901 [==============================] - 0s 508us/step - loss: 0.1848 - accuracy: 0.9154 - val_loss: 0.1942 - val_accuracy: 0.9110\n",
      "Epoch 37/100\n",
      "901/901 [==============================] - 0s 492us/step - loss: 0.1841 - accuracy: 0.9147 - val_loss: 0.1943 - val_accuracy: 0.9115\n",
      "Epoch 38/100\n",
      "901/901 [==============================] - 0s 492us/step - loss: 0.1836 - accuracy: 0.9160 - val_loss: 0.1929 - val_accuracy: 0.9112\n",
      "Epoch 39/100\n",
      "901/901 [==============================] - 0s 491us/step - loss: 0.1830 - accuracy: 0.9154 - val_loss: 0.1938 - val_accuracy: 0.9105\n",
      "Epoch 40/100\n",
      "901/901 [==============================] - 0s 485us/step - loss: 0.1825 - accuracy: 0.9155 - val_loss: 0.1927 - val_accuracy: 0.9115\n",
      "Epoch 41/100\n",
      "901/901 [==============================] - 0s 486us/step - loss: 0.1820 - accuracy: 0.9156 - val_loss: 0.1922 - val_accuracy: 0.9116\n",
      "Epoch 42/100\n",
      "901/901 [==============================] - 0s 494us/step - loss: 0.1816 - accuracy: 0.9161 - val_loss: 0.1918 - val_accuracy: 0.9120\n",
      "Epoch 43/100\n",
      "901/901 [==============================] - 0s 497us/step - loss: 0.1812 - accuracy: 0.9158 - val_loss: 0.1910 - val_accuracy: 0.9108\n",
      "Epoch 44/100\n",
      "901/901 [==============================] - 0s 492us/step - loss: 0.1807 - accuracy: 0.9157 - val_loss: 0.1912 - val_accuracy: 0.9115\n",
      "Epoch 45/100\n",
      "901/901 [==============================] - 0s 490us/step - loss: 0.1802 - accuracy: 0.9162 - val_loss: 0.1909 - val_accuracy: 0.9115\n",
      "Epoch 46/100\n",
      "901/901 [==============================] - 0s 494us/step - loss: 0.1798 - accuracy: 0.9163 - val_loss: 0.1905 - val_accuracy: 0.9107\n",
      "Epoch 47/100\n",
      "901/901 [==============================] - 0s 495us/step - loss: 0.1795 - accuracy: 0.9168 - val_loss: 0.1908 - val_accuracy: 0.9115\n",
      "Epoch 48/100\n",
      "901/901 [==============================] - 0s 493us/step - loss: 0.1791 - accuracy: 0.9163 - val_loss: 0.1905 - val_accuracy: 0.9116\n",
      "Epoch 49/100\n",
      "901/901 [==============================] - 0s 483us/step - loss: 0.1785 - accuracy: 0.9169 - val_loss: 0.1899 - val_accuracy: 0.9115\n",
      "Epoch 50/100\n",
      "901/901 [==============================] - 0s 498us/step - loss: 0.1781 - accuracy: 0.9167 - val_loss: 0.1901 - val_accuracy: 0.9099\n",
      "Epoch 51/100\n",
      "901/901 [==============================] - 1s 760us/step - loss: 0.1779 - accuracy: 0.9170 - val_loss: 0.1900 - val_accuracy: 0.9102\n",
      "Epoch 52/100\n",
      "901/901 [==============================] - 1s 623us/step - loss: 0.1776 - accuracy: 0.9165 - val_loss: 0.1898 - val_accuracy: 0.9110\n",
      "Epoch 53/100\n",
      "901/901 [==============================] - 0s 532us/step - loss: 0.1774 - accuracy: 0.9168 - val_loss: 0.1895 - val_accuracy: 0.9107\n",
      "Epoch 54/100\n",
      "901/901 [==============================] - 0s 530us/step - loss: 0.1770 - accuracy: 0.9168 - val_loss: 0.1895 - val_accuracy: 0.9103\n",
      "Epoch 55/100\n",
      "901/901 [==============================] - 0s 529us/step - loss: 0.1768 - accuracy: 0.9172 - val_loss: 0.1892 - val_accuracy: 0.9108\n",
      "Epoch 56/100\n",
      "901/901 [==============================] - 0s 490us/step - loss: 0.1762 - accuracy: 0.9164 - val_loss: 0.1901 - val_accuracy: 0.9110\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 0s 479us/step - loss: 0.1762 - accuracy: 0.9171 - val_loss: 0.1887 - val_accuracy: 0.9100\n",
      "Epoch 58/100\n",
      "901/901 [==============================] - 1s 585us/step - loss: 0.1758 - accuracy: 0.9176 - val_loss: 0.1890 - val_accuracy: 0.9102\n",
      "Epoch 59/100\n",
      "901/901 [==============================] - 1s 609us/step - loss: 0.1756 - accuracy: 0.9180 - val_loss: 0.1889 - val_accuracy: 0.9107\n",
      "Epoch 60/100\n",
      "901/901 [==============================] - 1s 630us/step - loss: 0.1752 - accuracy: 0.9176 - val_loss: 0.1886 - val_accuracy: 0.9110\n",
      "Epoch 61/100\n",
      "901/901 [==============================] - 1s 656us/step - loss: 0.1752 - accuracy: 0.9183 - val_loss: 0.1887 - val_accuracy: 0.9105\n",
      "Epoch 62/100\n",
      "901/901 [==============================] - 1s 589us/step - loss: 0.1749 - accuracy: 0.9185 - val_loss: 0.1885 - val_accuracy: 0.9110\n",
      "Epoch 63/100\n",
      "901/901 [==============================] - 0s 538us/step - loss: 0.1746 - accuracy: 0.9183 - val_loss: 0.1906 - val_accuracy: 0.9115\n",
      "Epoch 64/100\n",
      "901/901 [==============================] - 1s 565us/step - loss: 0.1743 - accuracy: 0.9184 - val_loss: 0.1888 - val_accuracy: 0.9105\n",
      "Epoch 65/100\n",
      "901/901 [==============================] - 0s 507us/step - loss: 0.1743 - accuracy: 0.9184 - val_loss: 0.1885 - val_accuracy: 0.9108\n",
      "Epoch 66/100\n",
      "901/901 [==============================] - 0s 506us/step - loss: 0.1738 - accuracy: 0.9187 - val_loss: 0.1887 - val_accuracy: 0.9124\n",
      "Epoch 67/100\n",
      "901/901 [==============================] - 0s 524us/step - loss: 0.1737 - accuracy: 0.9187 - val_loss: 0.1878 - val_accuracy: 0.9112\n",
      "Epoch 68/100\n",
      "901/901 [==============================] - 0s 487us/step - loss: 0.1735 - accuracy: 0.9189 - val_loss: 0.1888 - val_accuracy: 0.9112\n",
      "Epoch 69/100\n",
      "901/901 [==============================] - 0s 482us/step - loss: 0.1733 - accuracy: 0.9192 - val_loss: 0.1879 - val_accuracy: 0.9120\n",
      "Epoch 70/100\n",
      "901/901 [==============================] - 0s 487us/step - loss: 0.1731 - accuracy: 0.9191 - val_loss: 0.1876 - val_accuracy: 0.9107\n",
      "Epoch 71/100\n",
      "901/901 [==============================] - 1s 604us/step - loss: 0.1728 - accuracy: 0.9192 - val_loss: 0.1879 - val_accuracy: 0.9108\n",
      "Epoch 72/100\n",
      "901/901 [==============================] - 1s 604us/step - loss: 0.1729 - accuracy: 0.9188 - val_loss: 0.1887 - val_accuracy: 0.9121\n",
      "Epoch 73/100\n",
      "901/901 [==============================] - 1s 616us/step - loss: 0.1726 - accuracy: 0.9194 - val_loss: 0.1887 - val_accuracy: 0.9115\n",
      "Epoch 74/100\n",
      "901/901 [==============================] - 0s 541us/step - loss: 0.1725 - accuracy: 0.9197 - val_loss: 0.1876 - val_accuracy: 0.9113\n",
      "Epoch 75/100\n",
      "901/901 [==============================] - 0s 533us/step - loss: 0.1721 - accuracy: 0.9201 - val_loss: 0.1878 - val_accuracy: 0.9103\n",
      "Epoch 76/100\n",
      "901/901 [==============================] - 1s 593us/step - loss: 0.1719 - accuracy: 0.9196 - val_loss: 0.1877 - val_accuracy: 0.9118\n",
      "Epoch 77/100\n",
      "901/901 [==============================] - 1s 621us/step - loss: 0.1716 - accuracy: 0.9192 - val_loss: 0.1889 - val_accuracy: 0.9115\n",
      "Epoch 78/100\n",
      "901/901 [==============================] - 1s 585us/step - loss: 0.1716 - accuracy: 0.9200 - val_loss: 0.1874 - val_accuracy: 0.9115\n",
      "Epoch 79/100\n",
      "901/901 [==============================] - 0s 485us/step - loss: 0.1712 - accuracy: 0.9197 - val_loss: 0.1876 - val_accuracy: 0.9116\n",
      "Epoch 80/100\n",
      "901/901 [==============================] - 0s 493us/step - loss: 0.1713 - accuracy: 0.9201 - val_loss: 0.1878 - val_accuracy: 0.9116\n",
      "Epoch 81/100\n",
      "901/901 [==============================] - 0s 482us/step - loss: 0.1711 - accuracy: 0.9206 - val_loss: 0.1876 - val_accuracy: 0.9118\n",
      "Epoch 82/100\n",
      "901/901 [==============================] - 1s 714us/step - loss: 0.1708 - accuracy: 0.9211 - val_loss: 0.1890 - val_accuracy: 0.9129\n",
      "Epoch 83/100\n",
      "901/901 [==============================] - 1s 571us/step - loss: 0.1708 - accuracy: 0.9209 - val_loss: 0.1880 - val_accuracy: 0.9113\n",
      "Epoch 84/100\n",
      "901/901 [==============================] - 0s 483us/step - loss: 0.1707 - accuracy: 0.9203 - val_loss: 0.1876 - val_accuracy: 0.9123\n",
      "Epoch 85/100\n",
      "901/901 [==============================] - 0s 487us/step - loss: 0.1702 - accuracy: 0.9203 - val_loss: 0.1879 - val_accuracy: 0.9115\n",
      "Epoch 86/100\n",
      "901/901 [==============================] - 0s 485us/step - loss: 0.1702 - accuracy: 0.9210 - val_loss: 0.1878 - val_accuracy: 0.9120\n",
      "Epoch 87/100\n",
      "901/901 [==============================] - 1s 563us/step - loss: 0.1700 - accuracy: 0.9211 - val_loss: 0.1894 - val_accuracy: 0.9103\n",
      "Epoch 88/100\n",
      "901/901 [==============================] - 0s 543us/step - loss: 0.1698 - accuracy: 0.9206 - val_loss: 0.1876 - val_accuracy: 0.9107\n",
      "Epoch 89/100\n",
      "901/901 [==============================] - 0s 488us/step - loss: 0.1696 - accuracy: 0.9214 - val_loss: 0.1872 - val_accuracy: 0.9134\n",
      "Epoch 90/100\n",
      "901/901 [==============================] - 0s 549us/step - loss: 0.1696 - accuracy: 0.9206 - val_loss: 0.1875 - val_accuracy: 0.9129\n",
      "Epoch 91/100\n",
      "901/901 [==============================] - 0s 552us/step - loss: 0.1693 - accuracy: 0.9219 - val_loss: 0.1871 - val_accuracy: 0.9115\n",
      "Epoch 92/100\n",
      "901/901 [==============================] - 0s 504us/step - loss: 0.1691 - accuracy: 0.9214 - val_loss: 0.1882 - val_accuracy: 0.9103\n",
      "Epoch 93/100\n",
      "901/901 [==============================] - 0s 495us/step - loss: 0.1691 - accuracy: 0.9215 - val_loss: 0.1891 - val_accuracy: 0.9099\n",
      "Epoch 94/100\n",
      "901/901 [==============================] - 0s 480us/step - loss: 0.1690 - accuracy: 0.9211 - val_loss: 0.1874 - val_accuracy: 0.9116\n",
      "Epoch 95/100\n",
      "901/901 [==============================] - 0s 511us/step - loss: 0.1687 - accuracy: 0.9212 - val_loss: 0.1877 - val_accuracy: 0.9121\n",
      "Epoch 96/100\n",
      "901/901 [==============================] - 0s 537us/step - loss: 0.1686 - accuracy: 0.9219 - val_loss: 0.1893 - val_accuracy: 0.9108\n",
      "Epoch 97/100\n",
      "901/901 [==============================] - 0s 501us/step - loss: 0.1683 - accuracy: 0.9217 - val_loss: 0.1892 - val_accuracy: 0.9110\n",
      "Epoch 98/100\n",
      "901/901 [==============================] - 0s 479us/step - loss: 0.1683 - accuracy: 0.9219 - val_loss: 0.1877 - val_accuracy: 0.9112\n",
      "Epoch 99/100\n",
      "901/901 [==============================] - 0s 550us/step - loss: 0.1681 - accuracy: 0.9212 - val_loss: 0.1874 - val_accuracy: 0.9124\n",
      "Epoch 100/100\n",
      "901/901 [==============================] - 1s 566us/step - loss: 0.1680 - accuracy: 0.9219 - val_loss: 0.1886 - val_accuracy: 0.9103\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "epochs_medium = model.fit(X_train_scaled_ex, y_train_ex,\n",
    "                                epochs=100,\n",
    "                                batch_size=32,\n",
    "                                validation_data=(X_val_scaled_ex, y_val_ex))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958cc7d2",
   "metadata": {},
   "source": [
    "##### Low\n",
    "- Number of epochs are 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e241a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "901/901 [==============================] - 1s 576us/step - loss: 0.3696 - accuracy: 0.8844 - val_loss: 0.3139 - val_accuracy: 0.8846\n",
      "Epoch 2/50\n",
      "901/901 [==============================] - 0s 506us/step - loss: 0.2989 - accuracy: 0.8885 - val_loss: 0.2936 - val_accuracy: 0.8853\n",
      "Epoch 3/50\n",
      "901/901 [==============================] - 0s 495us/step - loss: 0.2837 - accuracy: 0.8917 - val_loss: 0.2823 - val_accuracy: 0.8896\n",
      "Epoch 4/50\n",
      "901/901 [==============================] - 0s 524us/step - loss: 0.2748 - accuracy: 0.8971 - val_loss: 0.2755 - val_accuracy: 0.8901\n",
      "Epoch 5/50\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.2683 - accuracy: 0.8992 - val_loss: 0.2695 - val_accuracy: 0.8930\n",
      "Epoch 6/50\n",
      "901/901 [==============================] - 0s 500us/step - loss: 0.2624 - accuracy: 0.9007 - val_loss: 0.2641 - val_accuracy: 0.8943\n",
      "Epoch 7/50\n",
      "901/901 [==============================] - 0s 503us/step - loss: 0.2562 - accuracy: 0.9013 - val_loss: 0.2577 - val_accuracy: 0.8958\n",
      "Epoch 8/50\n",
      "901/901 [==============================] - 0s 509us/step - loss: 0.2494 - accuracy: 0.9022 - val_loss: 0.2516 - val_accuracy: 0.8974\n",
      "Epoch 9/50\n",
      "901/901 [==============================] - 0s 507us/step - loss: 0.2427 - accuracy: 0.9035 - val_loss: 0.2449 - val_accuracy: 0.8989\n",
      "Epoch 10/50\n",
      "901/901 [==============================] - 0s 496us/step - loss: 0.2356 - accuracy: 0.9040 - val_loss: 0.2387 - val_accuracy: 0.8997\n",
      "Epoch 11/50\n",
      "901/901 [==============================] - 0s 504us/step - loss: 0.2286 - accuracy: 0.9048 - val_loss: 0.2316 - val_accuracy: 0.9016\n",
      "Epoch 12/50\n",
      "901/901 [==============================] - 0s 504us/step - loss: 0.2219 - accuracy: 0.9060 - val_loss: 0.2260 - val_accuracy: 0.9024\n",
      "Epoch 13/50\n",
      "901/901 [==============================] - 0s 496us/step - loss: 0.2162 - accuracy: 0.9075 - val_loss: 0.2234 - val_accuracy: 0.9013\n",
      "Epoch 14/50\n",
      "901/901 [==============================] - 0s 506us/step - loss: 0.2115 - accuracy: 0.9079 - val_loss: 0.2170 - val_accuracy: 0.9040\n",
      "Epoch 15/50\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.2077 - accuracy: 0.9082 - val_loss: 0.2136 - val_accuracy: 0.9045\n",
      "Epoch 16/50\n",
      "901/901 [==============================] - 0s 513us/step - loss: 0.2044 - accuracy: 0.9091 - val_loss: 0.2111 - val_accuracy: 0.9048\n",
      "Epoch 17/50\n",
      "901/901 [==============================] - 0s 517us/step - loss: 0.2019 - accuracy: 0.9110 - val_loss: 0.2089 - val_accuracy: 0.9061\n",
      "Epoch 18/50\n",
      "901/901 [==============================] - 0s 542us/step - loss: 0.1997 - accuracy: 0.9108 - val_loss: 0.2075 - val_accuracy: 0.9086\n",
      "Epoch 19/50\n",
      "901/901 [==============================] - 0s 493us/step - loss: 0.1978 - accuracy: 0.9121 - val_loss: 0.2061 - val_accuracy: 0.9089\n",
      "Epoch 20/50\n",
      "901/901 [==============================] - 0s 498us/step - loss: 0.1965 - accuracy: 0.9120 - val_loss: 0.2052 - val_accuracy: 0.9073\n",
      "Epoch 21/50\n",
      "901/901 [==============================] - 0s 498us/step - loss: 0.1952 - accuracy: 0.9126 - val_loss: 0.2049 - val_accuracy: 0.9073\n",
      "Epoch 22/50\n",
      "901/901 [==============================] - 0s 489us/step - loss: 0.1941 - accuracy: 0.9131 - val_loss: 0.2032 - val_accuracy: 0.9089\n",
      "Epoch 23/50\n",
      "901/901 [==============================] - 0s 491us/step - loss: 0.1932 - accuracy: 0.9136 - val_loss: 0.2024 - val_accuracy: 0.9073\n",
      "Epoch 24/50\n",
      "901/901 [==============================] - 0s 500us/step - loss: 0.1923 - accuracy: 0.9131 - val_loss: 0.2017 - val_accuracy: 0.9071\n",
      "Epoch 25/50\n",
      "901/901 [==============================] - 1s 556us/step - loss: 0.1912 - accuracy: 0.9135 - val_loss: 0.2011 - val_accuracy: 0.9071\n",
      "Epoch 26/50\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.1905 - accuracy: 0.9135 - val_loss: 0.2003 - val_accuracy: 0.9073\n",
      "Epoch 27/50\n",
      "901/901 [==============================] - 0s 507us/step - loss: 0.1898 - accuracy: 0.9138 - val_loss: 0.2003 - val_accuracy: 0.9073\n",
      "Epoch 28/50\n",
      "901/901 [==============================] - 0s 485us/step - loss: 0.1890 - accuracy: 0.9146 - val_loss: 0.1996 - val_accuracy: 0.9082\n",
      "Epoch 29/50\n",
      "901/901 [==============================] - 0s 505us/step - loss: 0.1882 - accuracy: 0.9137 - val_loss: 0.1987 - val_accuracy: 0.9078\n",
      "Epoch 30/50\n",
      "901/901 [==============================] - 0s 543us/step - loss: 0.1876 - accuracy: 0.9142 - val_loss: 0.1981 - val_accuracy: 0.9076\n",
      "Epoch 31/50\n",
      "901/901 [==============================] - 0s 523us/step - loss: 0.1871 - accuracy: 0.9147 - val_loss: 0.1976 - val_accuracy: 0.9086\n",
      "Epoch 32/50\n",
      "901/901 [==============================] - 0s 500us/step - loss: 0.1863 - accuracy: 0.9145 - val_loss: 0.1976 - val_accuracy: 0.9082\n",
      "Epoch 33/50\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.1859 - accuracy: 0.9148 - val_loss: 0.1972 - val_accuracy: 0.9079\n",
      "Epoch 34/50\n",
      "901/901 [==============================] - 0s 486us/step - loss: 0.1854 - accuracy: 0.9148 - val_loss: 0.1975 - val_accuracy: 0.9079\n",
      "Epoch 35/50\n",
      "901/901 [==============================] - 0s 487us/step - loss: 0.1847 - accuracy: 0.9151 - val_loss: 0.1961 - val_accuracy: 0.9095\n",
      "Epoch 36/50\n",
      "901/901 [==============================] - 0s 547us/step - loss: 0.1841 - accuracy: 0.9149 - val_loss: 0.1956 - val_accuracy: 0.9092\n",
      "Epoch 37/50\n",
      "901/901 [==============================] - 0s 519us/step - loss: 0.1837 - accuracy: 0.9150 - val_loss: 0.1956 - val_accuracy: 0.9094\n",
      "Epoch 38/50\n",
      "901/901 [==============================] - 0s 480us/step - loss: 0.1832 - accuracy: 0.9155 - val_loss: 0.1952 - val_accuracy: 0.9086\n",
      "Epoch 39/50\n",
      "901/901 [==============================] - 0s 478us/step - loss: 0.1827 - accuracy: 0.9156 - val_loss: 0.1956 - val_accuracy: 0.9078\n",
      "Epoch 40/50\n",
      "901/901 [==============================] - 0s 486us/step - loss: 0.1821 - accuracy: 0.9151 - val_loss: 0.1953 - val_accuracy: 0.9086\n",
      "Epoch 41/50\n",
      "901/901 [==============================] - 0s 497us/step - loss: 0.1819 - accuracy: 0.9161 - val_loss: 0.1945 - val_accuracy: 0.9071\n",
      "Epoch 42/50\n",
      "901/901 [==============================] - 0s 507us/step - loss: 0.1813 - accuracy: 0.9151 - val_loss: 0.1937 - val_accuracy: 0.9087\n",
      "Epoch 43/50\n",
      "901/901 [==============================] - 0s 500us/step - loss: 0.1808 - accuracy: 0.9154 - val_loss: 0.1947 - val_accuracy: 0.9089\n",
      "Epoch 44/50\n",
      "901/901 [==============================] - 0s 495us/step - loss: 0.1804 - accuracy: 0.9161 - val_loss: 0.1936 - val_accuracy: 0.9092\n",
      "Epoch 45/50\n",
      "901/901 [==============================] - 0s 492us/step - loss: 0.1800 - accuracy: 0.9156 - val_loss: 0.1934 - val_accuracy: 0.9099\n",
      "Epoch 46/50\n",
      "901/901 [==============================] - 0s 509us/step - loss: 0.1797 - accuracy: 0.9161 - val_loss: 0.1947 - val_accuracy: 0.9073\n",
      "Epoch 47/50\n",
      "901/901 [==============================] - 0s 483us/step - loss: 0.1792 - accuracy: 0.9158 - val_loss: 0.1936 - val_accuracy: 0.9090\n",
      "Epoch 48/50\n",
      "901/901 [==============================] - 0s 471us/step - loss: 0.1787 - accuracy: 0.9156 - val_loss: 0.1924 - val_accuracy: 0.9097\n",
      "Epoch 49/50\n",
      "901/901 [==============================] - 0s 481us/step - loss: 0.1786 - accuracy: 0.9162 - val_loss: 0.1928 - val_accuracy: 0.9084\n",
      "Epoch 50/50\n",
      "901/901 [==============================] - 0s 468us/step - loss: 0.1780 - accuracy: 0.9166 - val_loss: 0.1923 - val_accuracy: 0.9092\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "epochs_low = model.fit(X_train_scaled_ex, y_train_ex,\n",
    "                                epochs=50,\n",
    "                                batch_size=32,\n",
    "                                validation_data=(X_val_scaled_ex, y_val_ex))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab408476",
   "metadata": {},
   "source": [
    "##### High\n",
    "- Number of epochs are 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d5876ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "901/901 [==============================] - 1s 608us/step - loss: 0.3572 - accuracy: 0.8881 - val_loss: 0.3029 - val_accuracy: 0.8846\n",
      "Epoch 2/200\n",
      "901/901 [==============================] - 0s 518us/step - loss: 0.2908 - accuracy: 0.8892 - val_loss: 0.2847 - val_accuracy: 0.8878\n",
      "Epoch 3/200\n",
      "901/901 [==============================] - 0s 521us/step - loss: 0.2787 - accuracy: 0.8960 - val_loss: 0.2771 - val_accuracy: 0.8911\n",
      "Epoch 4/200\n",
      "901/901 [==============================] - 0s 504us/step - loss: 0.2719 - accuracy: 0.8990 - val_loss: 0.2720 - val_accuracy: 0.8958\n",
      "Epoch 5/200\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.2665 - accuracy: 0.9002 - val_loss: 0.2676 - val_accuracy: 0.8974\n",
      "Epoch 6/200\n",
      "901/901 [==============================] - 0s 497us/step - loss: 0.2611 - accuracy: 0.9017 - val_loss: 0.2623 - val_accuracy: 0.8982\n",
      "Epoch 7/200\n",
      "901/901 [==============================] - 0s 541us/step - loss: 0.2551 - accuracy: 0.9019 - val_loss: 0.2564 - val_accuracy: 0.8992\n",
      "Epoch 8/200\n",
      "901/901 [==============================] - 0s 514us/step - loss: 0.2486 - accuracy: 0.9024 - val_loss: 0.2499 - val_accuracy: 0.9014\n",
      "Epoch 9/200\n",
      "901/901 [==============================] - 0s 501us/step - loss: 0.2412 - accuracy: 0.9035 - val_loss: 0.2421 - val_accuracy: 0.9027\n",
      "Epoch 10/200\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.2335 - accuracy: 0.9052 - val_loss: 0.2344 - val_accuracy: 0.9055\n",
      "Epoch 11/200\n",
      "901/901 [==============================] - 0s 500us/step - loss: 0.2261 - accuracy: 0.9062 - val_loss: 0.2275 - val_accuracy: 0.9058\n",
      "Epoch 12/200\n",
      "901/901 [==============================] - 0s 506us/step - loss: 0.2196 - accuracy: 0.9081 - val_loss: 0.2214 - val_accuracy: 0.9061\n",
      "Epoch 13/200\n",
      "901/901 [==============================] - 0s 495us/step - loss: 0.2138 - accuracy: 0.9086 - val_loss: 0.2168 - val_accuracy: 0.9063\n",
      "Epoch 14/200\n",
      "901/901 [==============================] - 0s 545us/step - loss: 0.2093 - accuracy: 0.9089 - val_loss: 0.2134 - val_accuracy: 0.9074\n",
      "Epoch 15/200\n",
      "901/901 [==============================] - 0s 540us/step - loss: 0.2057 - accuracy: 0.9094 - val_loss: 0.2107 - val_accuracy: 0.9073\n",
      "Epoch 16/200\n",
      "901/901 [==============================] - 0s 537us/step - loss: 0.2028 - accuracy: 0.9104 - val_loss: 0.2086 - val_accuracy: 0.9086\n",
      "Epoch 17/200\n",
      "901/901 [==============================] - 0s 513us/step - loss: 0.2006 - accuracy: 0.9108 - val_loss: 0.2071 - val_accuracy: 0.9092\n",
      "Epoch 18/200\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.1989 - accuracy: 0.9117 - val_loss: 0.2058 - val_accuracy: 0.9078\n",
      "Epoch 19/200\n",
      "901/901 [==============================] - 0s 493us/step - loss: 0.1972 - accuracy: 0.9121 - val_loss: 0.2047 - val_accuracy: 0.9092\n",
      "Epoch 20/200\n",
      "901/901 [==============================] - 0s 522us/step - loss: 0.1956 - accuracy: 0.9128 - val_loss: 0.2050 - val_accuracy: 0.9074\n",
      "Epoch 21/200\n",
      "901/901 [==============================] - 1s 570us/step - loss: 0.1943 - accuracy: 0.9122 - val_loss: 0.2030 - val_accuracy: 0.9073\n",
      "Epoch 22/200\n",
      "901/901 [==============================] - 0s 520us/step - loss: 0.1932 - accuracy: 0.9128 - val_loss: 0.2024 - val_accuracy: 0.9078\n",
      "Epoch 23/200\n",
      "901/901 [==============================] - 0s 513us/step - loss: 0.1921 - accuracy: 0.9129 - val_loss: 0.2019 - val_accuracy: 0.9071\n",
      "Epoch 24/200\n",
      "901/901 [==============================] - 0s 521us/step - loss: 0.1913 - accuracy: 0.9134 - val_loss: 0.2008 - val_accuracy: 0.9078\n",
      "Epoch 25/200\n",
      "901/901 [==============================] - 0s 518us/step - loss: 0.1902 - accuracy: 0.9135 - val_loss: 0.2002 - val_accuracy: 0.9079\n",
      "Epoch 26/200\n",
      "901/901 [==============================] - 0s 541us/step - loss: 0.1894 - accuracy: 0.9135 - val_loss: 0.1999 - val_accuracy: 0.9089\n",
      "Epoch 27/200\n",
      "901/901 [==============================] - 0s 535us/step - loss: 0.1887 - accuracy: 0.9135 - val_loss: 0.1992 - val_accuracy: 0.9079\n",
      "Epoch 28/200\n",
      "901/901 [==============================] - 1s 567us/step - loss: 0.1879 - accuracy: 0.9138 - val_loss: 0.1988 - val_accuracy: 0.9079\n",
      "Epoch 29/200\n",
      "901/901 [==============================] - 0s 519us/step - loss: 0.1870 - accuracy: 0.9142 - val_loss: 0.1981 - val_accuracy: 0.9074\n",
      "Epoch 30/200\n",
      "901/901 [==============================] - 0s 532us/step - loss: 0.1864 - accuracy: 0.9137 - val_loss: 0.1978 - val_accuracy: 0.9071\n",
      "Epoch 31/200\n",
      "901/901 [==============================] - 0s 505us/step - loss: 0.1857 - accuracy: 0.9146 - val_loss: 0.1977 - val_accuracy: 0.9084\n",
      "Epoch 32/200\n",
      "901/901 [==============================] - 0s 492us/step - loss: 0.1848 - accuracy: 0.9146 - val_loss: 0.1979 - val_accuracy: 0.9078\n",
      "Epoch 33/200\n",
      "901/901 [==============================] - 0s 493us/step - loss: 0.1843 - accuracy: 0.9147 - val_loss: 0.1972 - val_accuracy: 0.9069\n",
      "Epoch 34/200\n",
      "901/901 [==============================] - 0s 489us/step - loss: 0.1838 - accuracy: 0.9145 - val_loss: 0.1964 - val_accuracy: 0.9069\n",
      "Epoch 35/200\n",
      "901/901 [==============================] - 0s 497us/step - loss: 0.1831 - accuracy: 0.9148 - val_loss: 0.1955 - val_accuracy: 0.9086\n",
      "Epoch 36/200\n",
      "901/901 [==============================] - 0s 490us/step - loss: 0.1825 - accuracy: 0.9154 - val_loss: 0.1971 - val_accuracy: 0.9079\n",
      "Epoch 37/200\n",
      "901/901 [==============================] - 0s 487us/step - loss: 0.1819 - accuracy: 0.9149 - val_loss: 0.1953 - val_accuracy: 0.9082\n",
      "Epoch 38/200\n",
      "901/901 [==============================] - 0s 481us/step - loss: 0.1814 - accuracy: 0.9147 - val_loss: 0.1946 - val_accuracy: 0.9089\n",
      "Epoch 39/200\n",
      "901/901 [==============================] - 0s 489us/step - loss: 0.1808 - accuracy: 0.9156 - val_loss: 0.1949 - val_accuracy: 0.9087\n",
      "Epoch 40/200\n",
      "901/901 [==============================] - 0s 486us/step - loss: 0.1805 - accuracy: 0.9151 - val_loss: 0.1943 - val_accuracy: 0.9089\n",
      "Epoch 41/200\n",
      "901/901 [==============================] - 0s 487us/step - loss: 0.1801 - accuracy: 0.9156 - val_loss: 0.1944 - val_accuracy: 0.9068\n",
      "Epoch 42/200\n",
      "901/901 [==============================] - 0s 482us/step - loss: 0.1794 - accuracy: 0.9153 - val_loss: 0.1951 - val_accuracy: 0.9100\n",
      "Epoch 43/200\n",
      "901/901 [==============================] - 0s 496us/step - loss: 0.1792 - accuracy: 0.9162 - val_loss: 0.1935 - val_accuracy: 0.9094\n",
      "Epoch 44/200\n",
      "901/901 [==============================] - 1s 558us/step - loss: 0.1787 - accuracy: 0.9159 - val_loss: 0.1933 - val_accuracy: 0.9092\n",
      "Epoch 45/200\n",
      "901/901 [==============================] - 0s 511us/step - loss: 0.1783 - accuracy: 0.9162 - val_loss: 0.1931 - val_accuracy: 0.9099\n",
      "Epoch 46/200\n",
      "901/901 [==============================] - 0s 477us/step - loss: 0.1778 - accuracy: 0.9163 - val_loss: 0.1925 - val_accuracy: 0.9090\n",
      "Epoch 47/200\n",
      "901/901 [==============================] - 1s 555us/step - loss: 0.1774 - accuracy: 0.9167 - val_loss: 0.1942 - val_accuracy: 0.9084\n",
      "Epoch 48/200\n",
      "901/901 [==============================] - 1s 637us/step - loss: 0.1770 - accuracy: 0.9174 - val_loss: 0.1926 - val_accuracy: 0.9087\n",
      "Epoch 49/200\n",
      "901/901 [==============================] - 0s 521us/step - loss: 0.1767 - accuracy: 0.9169 - val_loss: 0.1919 - val_accuracy: 0.9086\n",
      "Epoch 50/200\n",
      "901/901 [==============================] - 0s 512us/step - loss: 0.1762 - accuracy: 0.9171 - val_loss: 0.1918 - val_accuracy: 0.9089\n",
      "Epoch 51/200\n",
      "901/901 [==============================] - 1s 573us/step - loss: 0.1759 - accuracy: 0.9166 - val_loss: 0.1918 - val_accuracy: 0.9086\n",
      "Epoch 52/200\n",
      "901/901 [==============================] - 0s 482us/step - loss: 0.1755 - accuracy: 0.9172 - val_loss: 0.1945 - val_accuracy: 0.9076\n",
      "Epoch 53/200\n",
      "901/901 [==============================] - 0s 498us/step - loss: 0.1754 - accuracy: 0.9177 - val_loss: 0.1916 - val_accuracy: 0.9097\n",
      "Epoch 54/200\n",
      "901/901 [==============================] - 0s 481us/step - loss: 0.1749 - accuracy: 0.9169 - val_loss: 0.1916 - val_accuracy: 0.9107\n",
      "Epoch 55/200\n",
      "901/901 [==============================] - 1s 565us/step - loss: 0.1748 - accuracy: 0.9174 - val_loss: 0.1909 - val_accuracy: 0.9107\n",
      "Epoch 56/200\n",
      "901/901 [==============================] - 0s 507us/step - loss: 0.1743 - accuracy: 0.9172 - val_loss: 0.1910 - val_accuracy: 0.9095\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 0s 492us/step - loss: 0.1741 - accuracy: 0.9177 - val_loss: 0.1911 - val_accuracy: 0.9094\n",
      "Epoch 58/200\n",
      "901/901 [==============================] - 0s 530us/step - loss: 0.1738 - accuracy: 0.9183 - val_loss: 0.1907 - val_accuracy: 0.9087\n",
      "Epoch 59/200\n",
      "901/901 [==============================] - 0s 501us/step - loss: 0.1735 - accuracy: 0.9181 - val_loss: 0.1905 - val_accuracy: 0.9100\n",
      "Epoch 60/200\n",
      "901/901 [==============================] - 0s 527us/step - loss: 0.1732 - accuracy: 0.9183 - val_loss: 0.1905 - val_accuracy: 0.9095\n",
      "Epoch 61/200\n",
      "901/901 [==============================] - 0s 510us/step - loss: 0.1729 - accuracy: 0.9185 - val_loss: 0.1903 - val_accuracy: 0.9090\n",
      "Epoch 62/200\n",
      "901/901 [==============================] - 0s 473us/step - loss: 0.1727 - accuracy: 0.9186 - val_loss: 0.1907 - val_accuracy: 0.9100\n",
      "Epoch 63/200\n",
      "901/901 [==============================] - 0s 502us/step - loss: 0.1725 - accuracy: 0.9190 - val_loss: 0.1904 - val_accuracy: 0.9103\n",
      "Epoch 64/200\n",
      "901/901 [==============================] - 0s 479us/step - loss: 0.1721 - accuracy: 0.9189 - val_loss: 0.1901 - val_accuracy: 0.9112\n",
      "Epoch 65/200\n",
      "901/901 [==============================] - 0s 466us/step - loss: 0.1720 - accuracy: 0.9190 - val_loss: 0.1905 - val_accuracy: 0.9102\n",
      "Epoch 66/200\n",
      "901/901 [==============================] - 0s 472us/step - loss: 0.1717 - accuracy: 0.9190 - val_loss: 0.1897 - val_accuracy: 0.9113\n",
      "Epoch 67/200\n",
      "901/901 [==============================] - 0s 552us/step - loss: 0.1715 - accuracy: 0.9194 - val_loss: 0.1909 - val_accuracy: 0.9107\n",
      "Epoch 68/200\n",
      "901/901 [==============================] - 0s 525us/step - loss: 0.1712 - accuracy: 0.9198 - val_loss: 0.1911 - val_accuracy: 0.9097\n",
      "Epoch 69/200\n",
      "901/901 [==============================] - 0s 528us/step - loss: 0.1711 - accuracy: 0.9195 - val_loss: 0.1900 - val_accuracy: 0.9113\n",
      "Epoch 70/200\n",
      "901/901 [==============================] - 1s 574us/step - loss: 0.1708 - accuracy: 0.9202 - val_loss: 0.1896 - val_accuracy: 0.9108\n",
      "Epoch 71/200\n",
      "901/901 [==============================] - 0s 520us/step - loss: 0.1705 - accuracy: 0.9199 - val_loss: 0.1909 - val_accuracy: 0.9092\n",
      "Epoch 72/200\n",
      "901/901 [==============================] - 1s 559us/step - loss: 0.1703 - accuracy: 0.9203 - val_loss: 0.1892 - val_accuracy: 0.9113\n",
      "Epoch 73/200\n",
      "901/901 [==============================] - 1s 559us/step - loss: 0.1701 - accuracy: 0.9201 - val_loss: 0.1898 - val_accuracy: 0.9115\n",
      "Epoch 74/200\n",
      "901/901 [==============================] - 1s 566us/step - loss: 0.1699 - accuracy: 0.9198 - val_loss: 0.1896 - val_accuracy: 0.9110\n",
      "Epoch 75/200\n",
      "901/901 [==============================] - 0s 476us/step - loss: 0.1698 - accuracy: 0.9209 - val_loss: 0.1895 - val_accuracy: 0.9107\n",
      "Epoch 76/200\n",
      "901/901 [==============================] - 0s 476us/step - loss: 0.1695 - accuracy: 0.9201 - val_loss: 0.1900 - val_accuracy: 0.9113\n",
      "Epoch 77/200\n",
      "901/901 [==============================] - 0s 486us/step - loss: 0.1692 - accuracy: 0.9206 - val_loss: 0.1895 - val_accuracy: 0.9110\n",
      "Epoch 78/200\n",
      "901/901 [==============================] - 0s 496us/step - loss: 0.1692 - accuracy: 0.9213 - val_loss: 0.1895 - val_accuracy: 0.9108\n",
      "Epoch 79/200\n",
      "901/901 [==============================] - 0s 492us/step - loss: 0.1688 - accuracy: 0.9219 - val_loss: 0.1895 - val_accuracy: 0.9107\n",
      "Epoch 80/200\n",
      "901/901 [==============================] - 0s 487us/step - loss: 0.1686 - accuracy: 0.9224 - val_loss: 0.1916 - val_accuracy: 0.9113\n",
      "Epoch 81/200\n",
      "901/901 [==============================] - 0s 493us/step - loss: 0.1685 - accuracy: 0.9209 - val_loss: 0.1914 - val_accuracy: 0.9105\n",
      "Epoch 82/200\n",
      "901/901 [==============================] - 0s 471us/step - loss: 0.1683 - accuracy: 0.9220 - val_loss: 0.1908 - val_accuracy: 0.9110\n",
      "Epoch 83/200\n",
      "901/901 [==============================] - 0s 478us/step - loss: 0.1683 - accuracy: 0.9214 - val_loss: 0.1909 - val_accuracy: 0.9115\n",
      "Epoch 84/200\n",
      "901/901 [==============================] - 0s 472us/step - loss: 0.1681 - accuracy: 0.9218 - val_loss: 0.1913 - val_accuracy: 0.9105\n",
      "Epoch 85/200\n",
      "901/901 [==============================] - 0s 490us/step - loss: 0.1676 - accuracy: 0.9223 - val_loss: 0.1897 - val_accuracy: 0.9128\n",
      "Epoch 86/200\n",
      "901/901 [==============================] - 1s 562us/step - loss: 0.1675 - accuracy: 0.9216 - val_loss: 0.1898 - val_accuracy: 0.9121\n",
      "Epoch 87/200\n",
      "901/901 [==============================] - 0s 537us/step - loss: 0.1674 - accuracy: 0.9221 - val_loss: 0.1893 - val_accuracy: 0.9112\n",
      "Epoch 88/200\n",
      "901/901 [==============================] - 1s 599us/step - loss: 0.1674 - accuracy: 0.9220 - val_loss: 0.1895 - val_accuracy: 0.9124\n",
      "Epoch 89/200\n",
      "901/901 [==============================] - 1s 573us/step - loss: 0.1672 - accuracy: 0.9219 - val_loss: 0.1898 - val_accuracy: 0.9128\n",
      "Epoch 90/200\n",
      "901/901 [==============================] - 1s 629us/step - loss: 0.1669 - accuracy: 0.9220 - val_loss: 0.1906 - val_accuracy: 0.9099\n",
      "Epoch 91/200\n",
      "901/901 [==============================] - 1s 577us/step - loss: 0.1667 - accuracy: 0.9221 - val_loss: 0.1893 - val_accuracy: 0.9120\n",
      "Epoch 92/200\n",
      "901/901 [==============================] - 1s 565us/step - loss: 0.1667 - accuracy: 0.9229 - val_loss: 0.1894 - val_accuracy: 0.9116\n",
      "Epoch 93/200\n",
      "901/901 [==============================] - 0s 551us/step - loss: 0.1664 - accuracy: 0.9225 - val_loss: 0.1893 - val_accuracy: 0.9107\n",
      "Epoch 94/200\n",
      "901/901 [==============================] - 0s 528us/step - loss: 0.1664 - accuracy: 0.9228 - val_loss: 0.1897 - val_accuracy: 0.9116\n",
      "Epoch 95/200\n",
      "901/901 [==============================] - 0s 506us/step - loss: 0.1659 - accuracy: 0.9234 - val_loss: 0.1903 - val_accuracy: 0.9115\n",
      "Epoch 96/200\n",
      "901/901 [==============================] - 0s 483us/step - loss: 0.1660 - accuracy: 0.9232 - val_loss: 0.1896 - val_accuracy: 0.9118\n",
      "Epoch 97/200\n",
      "901/901 [==============================] - 0s 478us/step - loss: 0.1660 - accuracy: 0.9230 - val_loss: 0.1894 - val_accuracy: 0.9124\n",
      "Epoch 98/200\n",
      "901/901 [==============================] - 0s 482us/step - loss: 0.1656 - accuracy: 0.9235 - val_loss: 0.1897 - val_accuracy: 0.9121\n",
      "Epoch 99/200\n",
      "901/901 [==============================] - 1s 555us/step - loss: 0.1655 - accuracy: 0.9229 - val_loss: 0.1894 - val_accuracy: 0.9118\n",
      "Epoch 100/200\n",
      "901/901 [==============================] - 0s 505us/step - loss: 0.1654 - accuracy: 0.9231 - val_loss: 0.1908 - val_accuracy: 0.9118\n",
      "Epoch 101/200\n",
      "901/901 [==============================] - 0s 503us/step - loss: 0.1652 - accuracy: 0.9236 - val_loss: 0.1897 - val_accuracy: 0.9116\n",
      "Epoch 102/200\n",
      "901/901 [==============================] - 0s 492us/step - loss: 0.1651 - accuracy: 0.9234 - val_loss: 0.1900 - val_accuracy: 0.9107\n",
      "Epoch 103/200\n",
      "901/901 [==============================] - 1s 592us/step - loss: 0.1651 - accuracy: 0.9235 - val_loss: 0.1900 - val_accuracy: 0.9112\n",
      "Epoch 104/200\n",
      "901/901 [==============================] - 1s 602us/step - loss: 0.1649 - accuracy: 0.9240 - val_loss: 0.1896 - val_accuracy: 0.9107\n",
      "Epoch 105/200\n",
      "901/901 [==============================] - 0s 522us/step - loss: 0.1647 - accuracy: 0.9236 - val_loss: 0.1900 - val_accuracy: 0.9116\n",
      "Epoch 106/200\n",
      "901/901 [==============================] - 0s 529us/step - loss: 0.1645 - accuracy: 0.9237 - val_loss: 0.1894 - val_accuracy: 0.9115\n",
      "Epoch 107/200\n",
      "901/901 [==============================] - 0s 531us/step - loss: 0.1643 - accuracy: 0.9233 - val_loss: 0.1900 - val_accuracy: 0.9115\n",
      "Epoch 108/200\n",
      "901/901 [==============================] - 0s 519us/step - loss: 0.1642 - accuracy: 0.9241 - val_loss: 0.1896 - val_accuracy: 0.9110\n",
      "Epoch 109/200\n",
      "901/901 [==============================] - 1s 567us/step - loss: 0.1640 - accuracy: 0.9240 - val_loss: 0.1907 - val_accuracy: 0.9112\n",
      "Epoch 110/200\n",
      "901/901 [==============================] - 0s 533us/step - loss: 0.1640 - accuracy: 0.9240 - val_loss: 0.1906 - val_accuracy: 0.9112\n",
      "Epoch 111/200\n",
      "901/901 [==============================] - 0s 495us/step - loss: 0.1640 - accuracy: 0.9248 - val_loss: 0.1914 - val_accuracy: 0.9095\n",
      "Epoch 112/200\n",
      "901/901 [==============================] - 0s 491us/step - loss: 0.1638 - accuracy: 0.9237 - val_loss: 0.1899 - val_accuracy: 0.9115\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 0s 553us/step - loss: 0.1635 - accuracy: 0.9241 - val_loss: 0.1895 - val_accuracy: 0.9118\n",
      "Epoch 114/200\n",
      "901/901 [==============================] - 0s 478us/step - loss: 0.1633 - accuracy: 0.9250 - val_loss: 0.1902 - val_accuracy: 0.9108\n",
      "Epoch 115/200\n",
      "901/901 [==============================] - 0s 478us/step - loss: 0.1633 - accuracy: 0.9241 - val_loss: 0.1904 - val_accuracy: 0.9115\n",
      "Epoch 116/200\n",
      "901/901 [==============================] - 0s 501us/step - loss: 0.1632 - accuracy: 0.9245 - val_loss: 0.1904 - val_accuracy: 0.9118\n",
      "Epoch 117/200\n",
      "901/901 [==============================] - 0s 481us/step - loss: 0.1631 - accuracy: 0.9245 - val_loss: 0.1921 - val_accuracy: 0.9099\n",
      "Epoch 118/200\n",
      "901/901 [==============================] - 0s 479us/step - loss: 0.1630 - accuracy: 0.9250 - val_loss: 0.1903 - val_accuracy: 0.9121\n",
      "Epoch 119/200\n",
      "901/901 [==============================] - 0s 507us/step - loss: 0.1628 - accuracy: 0.9245 - val_loss: 0.1913 - val_accuracy: 0.9107\n",
      "Epoch 120/200\n",
      "901/901 [==============================] - 0s 496us/step - loss: 0.1628 - accuracy: 0.9248 - val_loss: 0.1901 - val_accuracy: 0.9112\n",
      "Epoch 121/200\n",
      "901/901 [==============================] - 1s 614us/step - loss: 0.1625 - accuracy: 0.9247 - val_loss: 0.1925 - val_accuracy: 0.9097\n",
      "Epoch 122/200\n",
      "901/901 [==============================] - 1s 635us/step - loss: 0.1625 - accuracy: 0.9248 - val_loss: 0.1902 - val_accuracy: 0.9110\n",
      "Epoch 123/200\n",
      "901/901 [==============================] - 1s 653us/step - loss: 0.1623 - accuracy: 0.9248 - val_loss: 0.1909 - val_accuracy: 0.9108\n",
      "Epoch 124/200\n",
      "901/901 [==============================] - 0s 507us/step - loss: 0.1623 - accuracy: 0.9252 - val_loss: 0.1902 - val_accuracy: 0.9113\n",
      "Epoch 125/200\n",
      "901/901 [==============================] - 0s 531us/step - loss: 0.1621 - accuracy: 0.9248 - val_loss: 0.1906 - val_accuracy: 0.9097\n",
      "Epoch 126/200\n",
      "901/901 [==============================] - 1s 558us/step - loss: 0.1619 - accuracy: 0.9248 - val_loss: 0.1906 - val_accuracy: 0.9112\n",
      "Epoch 127/200\n",
      "901/901 [==============================] - 0s 552us/step - loss: 0.1619 - accuracy: 0.9253 - val_loss: 0.1919 - val_accuracy: 0.9113\n",
      "Epoch 128/200\n",
      "901/901 [==============================] - 0s 527us/step - loss: 0.1617 - accuracy: 0.9252 - val_loss: 0.1913 - val_accuracy: 0.9092\n",
      "Epoch 129/200\n",
      "901/901 [==============================] - 1s 563us/step - loss: 0.1615 - accuracy: 0.9252 - val_loss: 0.1906 - val_accuracy: 0.9123\n",
      "Epoch 130/200\n",
      "901/901 [==============================] - 0s 543us/step - loss: 0.1613 - accuracy: 0.9254 - val_loss: 0.1910 - val_accuracy: 0.9103\n",
      "Epoch 131/200\n",
      "901/901 [==============================] - 0s 553us/step - loss: 0.1615 - accuracy: 0.9250 - val_loss: 0.1901 - val_accuracy: 0.9107\n",
      "Epoch 132/200\n",
      "901/901 [==============================] - 1s 616us/step - loss: 0.1614 - accuracy: 0.9252 - val_loss: 0.1899 - val_accuracy: 0.9115\n",
      "Epoch 133/200\n",
      "901/901 [==============================] - 1s 571us/step - loss: 0.1609 - accuracy: 0.9254 - val_loss: 0.1912 - val_accuracy: 0.9124\n",
      "Epoch 134/200\n",
      "901/901 [==============================] - 1s 623us/step - loss: 0.1609 - accuracy: 0.9256 - val_loss: 0.1909 - val_accuracy: 0.9103\n",
      "Epoch 135/200\n",
      "901/901 [==============================] - 1s 639us/step - loss: 0.1610 - accuracy: 0.9252 - val_loss: 0.1909 - val_accuracy: 0.9095\n",
      "Epoch 136/200\n",
      "901/901 [==============================] - 1s 640us/step - loss: 0.1607 - accuracy: 0.9260 - val_loss: 0.1905 - val_accuracy: 0.9100\n",
      "Epoch 137/200\n",
      "901/901 [==============================] - 1s 567us/step - loss: 0.1607 - accuracy: 0.9253 - val_loss: 0.1907 - val_accuracy: 0.9116\n",
      "Epoch 138/200\n",
      "901/901 [==============================] - 1s 570us/step - loss: 0.1605 - accuracy: 0.9260 - val_loss: 0.1910 - val_accuracy: 0.9092\n",
      "Epoch 139/200\n",
      "901/901 [==============================] - 1s 635us/step - loss: 0.1604 - accuracy: 0.9263 - val_loss: 0.1927 - val_accuracy: 0.9099\n",
      "Epoch 140/200\n",
      "901/901 [==============================] - 1s 605us/step - loss: 0.1604 - accuracy: 0.9258 - val_loss: 0.1902 - val_accuracy: 0.9108\n",
      "Epoch 141/200\n",
      "901/901 [==============================] - 1s 588us/step - loss: 0.1602 - accuracy: 0.9261 - val_loss: 0.1910 - val_accuracy: 0.9102\n",
      "Epoch 142/200\n",
      "901/901 [==============================] - 1s 621us/step - loss: 0.1601 - accuracy: 0.9262 - val_loss: 0.1905 - val_accuracy: 0.9107\n",
      "Epoch 143/200\n",
      "901/901 [==============================] - 1s 640us/step - loss: 0.1601 - accuracy: 0.9262 - val_loss: 0.1908 - val_accuracy: 0.9107\n",
      "Epoch 144/200\n",
      "901/901 [==============================] - 1s 622us/step - loss: 0.1598 - accuracy: 0.9263 - val_loss: 0.1916 - val_accuracy: 0.9107\n",
      "Epoch 145/200\n",
      "901/901 [==============================] - 1s 579us/step - loss: 0.1596 - accuracy: 0.9266 - val_loss: 0.1918 - val_accuracy: 0.9108\n",
      "Epoch 146/200\n",
      "901/901 [==============================] - 1s 589us/step - loss: 0.1596 - accuracy: 0.9259 - val_loss: 0.1916 - val_accuracy: 0.9095\n",
      "Epoch 147/200\n",
      "901/901 [==============================] - 1s 563us/step - loss: 0.1595 - accuracy: 0.9261 - val_loss: 0.1914 - val_accuracy: 0.9118\n",
      "Epoch 148/200\n",
      "901/901 [==============================] - 1s 568us/step - loss: 0.1594 - accuracy: 0.9264 - val_loss: 0.1910 - val_accuracy: 0.9097\n",
      "Epoch 149/200\n",
      "901/901 [==============================] - 1s 570us/step - loss: 0.1592 - accuracy: 0.9266 - val_loss: 0.1927 - val_accuracy: 0.9089\n",
      "Epoch 150/200\n",
      "901/901 [==============================] - 1s 556us/step - loss: 0.1590 - accuracy: 0.9268 - val_loss: 0.1910 - val_accuracy: 0.9108\n",
      "Epoch 151/200\n",
      "901/901 [==============================] - 1s 567us/step - loss: 0.1591 - accuracy: 0.9267 - val_loss: 0.1912 - val_accuracy: 0.9108\n",
      "Epoch 152/200\n",
      "901/901 [==============================] - 1s 572us/step - loss: 0.1588 - accuracy: 0.9265 - val_loss: 0.1940 - val_accuracy: 0.9118\n",
      "Epoch 153/200\n",
      "901/901 [==============================] - 1s 564us/step - loss: 0.1590 - accuracy: 0.9270 - val_loss: 0.1924 - val_accuracy: 0.9097\n",
      "Epoch 154/200\n",
      "901/901 [==============================] - 1s 561us/step - loss: 0.1586 - accuracy: 0.9277 - val_loss: 0.1922 - val_accuracy: 0.9102\n",
      "Epoch 155/200\n",
      "901/901 [==============================] - 0s 553us/step - loss: 0.1587 - accuracy: 0.9271 - val_loss: 0.1918 - val_accuracy: 0.9103\n",
      "Epoch 156/200\n",
      "901/901 [==============================] - 1s 561us/step - loss: 0.1586 - accuracy: 0.9270 - val_loss: 0.1926 - val_accuracy: 0.9108\n",
      "Epoch 157/200\n",
      "901/901 [==============================] - 1s 567us/step - loss: 0.1582 - accuracy: 0.9271 - val_loss: 0.1919 - val_accuracy: 0.9108\n",
      "Epoch 158/200\n",
      "901/901 [==============================] - 1s 572us/step - loss: 0.1583 - accuracy: 0.9273 - val_loss: 0.1916 - val_accuracy: 0.9095\n",
      "Epoch 159/200\n",
      "901/901 [==============================] - 1s 560us/step - loss: 0.1582 - accuracy: 0.9281 - val_loss: 0.1924 - val_accuracy: 0.9108\n",
      "Epoch 160/200\n",
      "901/901 [==============================] - 1s 556us/step - loss: 0.1581 - accuracy: 0.9266 - val_loss: 0.1937 - val_accuracy: 0.9115\n",
      "Epoch 161/200\n",
      "901/901 [==============================] - 1s 559us/step - loss: 0.1577 - accuracy: 0.9270 - val_loss: 0.1914 - val_accuracy: 0.9094\n",
      "Epoch 162/200\n",
      "901/901 [==============================] - 1s 559us/step - loss: 0.1578 - accuracy: 0.9270 - val_loss: 0.1923 - val_accuracy: 0.9112\n",
      "Epoch 163/200\n",
      "901/901 [==============================] - 1s 560us/step - loss: 0.1577 - accuracy: 0.9266 - val_loss: 0.1922 - val_accuracy: 0.9103\n",
      "Epoch 164/200\n",
      "901/901 [==============================] - 0s 554us/step - loss: 0.1576 - accuracy: 0.9276 - val_loss: 0.1914 - val_accuracy: 0.9102\n",
      "Epoch 165/200\n",
      "901/901 [==============================] - 1s 568us/step - loss: 0.1576 - accuracy: 0.9280 - val_loss: 0.1934 - val_accuracy: 0.9097\n",
      "Epoch 166/200\n",
      "901/901 [==============================] - 1s 556us/step - loss: 0.1575 - accuracy: 0.9274 - val_loss: 0.1921 - val_accuracy: 0.9108\n",
      "Epoch 167/200\n",
      "901/901 [==============================] - 1s 558us/step - loss: 0.1572 - accuracy: 0.9276 - val_loss: 0.1923 - val_accuracy: 0.9086\n",
      "Epoch 168/200\n",
      "901/901 [==============================] - 1s 557us/step - loss: 0.1571 - accuracy: 0.9279 - val_loss: 0.1936 - val_accuracy: 0.9097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "901/901 [==============================] - 1s 558us/step - loss: 0.1571 - accuracy: 0.9283 - val_loss: 0.1944 - val_accuracy: 0.9099\n",
      "Epoch 170/200\n",
      "901/901 [==============================] - 0s 552us/step - loss: 0.1571 - accuracy: 0.9276 - val_loss: 0.1931 - val_accuracy: 0.9105\n",
      "Epoch 171/200\n",
      "901/901 [==============================] - 1s 555us/step - loss: 0.1570 - accuracy: 0.9279 - val_loss: 0.1918 - val_accuracy: 0.9107\n",
      "Epoch 172/200\n",
      "901/901 [==============================] - 1s 565us/step - loss: 0.1568 - accuracy: 0.9282 - val_loss: 0.1923 - val_accuracy: 0.9095\n",
      "Epoch 173/200\n",
      "901/901 [==============================] - 1s 560us/step - loss: 0.1566 - accuracy: 0.9285 - val_loss: 0.1927 - val_accuracy: 0.9110\n",
      "Epoch 174/200\n",
      "901/901 [==============================] - 1s 557us/step - loss: 0.1567 - accuracy: 0.9291 - val_loss: 0.1928 - val_accuracy: 0.9097\n",
      "Epoch 175/200\n",
      "901/901 [==============================] - 1s 555us/step - loss: 0.1565 - accuracy: 0.9283 - val_loss: 0.1923 - val_accuracy: 0.9095\n",
      "Epoch 176/200\n",
      "901/901 [==============================] - 1s 564us/step - loss: 0.1563 - accuracy: 0.9282 - val_loss: 0.1926 - val_accuracy: 0.9112\n",
      "Epoch 177/200\n",
      "901/901 [==============================] - 1s 557us/step - loss: 0.1565 - accuracy: 0.9281 - val_loss: 0.1939 - val_accuracy: 0.9105\n",
      "Epoch 178/200\n",
      "901/901 [==============================] - 1s 558us/step - loss: 0.1560 - accuracy: 0.9284 - val_loss: 0.1926 - val_accuracy: 0.9076\n",
      "Epoch 179/200\n",
      "901/901 [==============================] - 0s 554us/step - loss: 0.1562 - accuracy: 0.9288 - val_loss: 0.1932 - val_accuracy: 0.9095\n",
      "Epoch 180/200\n",
      "901/901 [==============================] - 1s 563us/step - loss: 0.1560 - accuracy: 0.9283 - val_loss: 0.1933 - val_accuracy: 0.9102\n",
      "Epoch 181/200\n",
      "901/901 [==============================] - 1s 557us/step - loss: 0.1561 - accuracy: 0.9287 - val_loss: 0.1930 - val_accuracy: 0.9100\n",
      "Epoch 182/200\n",
      "901/901 [==============================] - 1s 565us/step - loss: 0.1558 - accuracy: 0.9288 - val_loss: 0.1925 - val_accuracy: 0.9105\n",
      "Epoch 183/200\n",
      "901/901 [==============================] - 1s 566us/step - loss: 0.1556 - accuracy: 0.9283 - val_loss: 0.1962 - val_accuracy: 0.9131\n",
      "Epoch 184/200\n",
      "901/901 [==============================] - 1s 560us/step - loss: 0.1557 - accuracy: 0.9287 - val_loss: 0.1933 - val_accuracy: 0.9120\n",
      "Epoch 185/200\n",
      "901/901 [==============================] - 1s 565us/step - loss: 0.1557 - accuracy: 0.9282 - val_loss: 0.1936 - val_accuracy: 0.9102\n",
      "Epoch 186/200\n",
      "901/901 [==============================] - 1s 559us/step - loss: 0.1553 - accuracy: 0.9283 - val_loss: 0.1930 - val_accuracy: 0.9105\n",
      "Epoch 187/200\n",
      "901/901 [==============================] - 0s 553us/step - loss: 0.1553 - accuracy: 0.9287 - val_loss: 0.1935 - val_accuracy: 0.9108\n",
      "Epoch 188/200\n",
      "901/901 [==============================] - 0s 552us/step - loss: 0.1552 - accuracy: 0.9291 - val_loss: 0.1942 - val_accuracy: 0.9073\n",
      "Epoch 189/200\n",
      "901/901 [==============================] - 1s 575us/step - loss: 0.1553 - accuracy: 0.9296 - val_loss: 0.1935 - val_accuracy: 0.9090\n",
      "Epoch 190/200\n",
      "901/901 [==============================] - 1s 558us/step - loss: 0.1550 - accuracy: 0.9290 - val_loss: 0.1935 - val_accuracy: 0.9094\n",
      "Epoch 191/200\n",
      "901/901 [==============================] - 1s 564us/step - loss: 0.1550 - accuracy: 0.9293 - val_loss: 0.1938 - val_accuracy: 0.9108\n",
      "Epoch 192/200\n",
      "901/901 [==============================] - 1s 560us/step - loss: 0.1548 - accuracy: 0.9289 - val_loss: 0.1937 - val_accuracy: 0.9100\n",
      "Epoch 193/200\n",
      "901/901 [==============================] - 1s 862us/step - loss: 0.1548 - accuracy: 0.9297 - val_loss: 0.1933 - val_accuracy: 0.9108\n",
      "Epoch 194/200\n",
      "901/901 [==============================] - 1s 739us/step - loss: 0.1548 - accuracy: 0.9295 - val_loss: 0.1935 - val_accuracy: 0.9068\n",
      "Epoch 195/200\n",
      "901/901 [==============================] - 1s 581us/step - loss: 0.1547 - accuracy: 0.9295 - val_loss: 0.1940 - val_accuracy: 0.9092\n",
      "Epoch 196/200\n",
      "901/901 [==============================] - 1s 781us/step - loss: 0.1544 - accuracy: 0.9299 - val_loss: 0.1938 - val_accuracy: 0.9079\n",
      "Epoch 197/200\n",
      "901/901 [==============================] - 1s 574us/step - loss: 0.1545 - accuracy: 0.9290 - val_loss: 0.1939 - val_accuracy: 0.9092\n",
      "Epoch 198/200\n",
      "901/901 [==============================] - 1s 558us/step - loss: 0.1544 - accuracy: 0.9292 - val_loss: 0.1936 - val_accuracy: 0.9066\n",
      "Epoch 199/200\n",
      "901/901 [==============================] - 1s 602us/step - loss: 0.1544 - accuracy: 0.9292 - val_loss: 0.1936 - val_accuracy: 0.9089\n",
      "Epoch 200/200\n",
      "901/901 [==============================] - 1s 607us/step - loss: 0.1543 - accuracy: 0.9293 - val_loss: 0.1940 - val_accuracy: 0.9079\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "epochs_high = model.fit(X_train_scaled_ex, y_train_ex,\n",
    "                                epochs=200,\n",
    "                                batch_size=32,\n",
    "                                validation_data=(X_val_scaled_ex, y_val_ex))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9980c6e0",
   "metadata": {},
   "source": [
    "#### Task 12\n",
    "##### Create a dataframe with the loss and accuracy for training and validation data along with their epochs.\n",
    "##### Plot the validation accuracy and loss curves for the models with different number of epochs to analyze and compare the results.\n",
    "#### Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "937ca3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_sizes = []\n",
    "for exp, result in zip([epochs_medium, epochs_low, epochs_high], [\"100\", \"50\", \"200\"]):\n",
    "  df = pd.DataFrame.from_dict(exp.history)\n",
    "  df['epoch'] = df.index.values\n",
    "  df['epochs'] = result\n",
    "  epochs_sizes.append(df)\n",
    "df = pd.concat(epochs_sizes)\n",
    "df['epochs'] = df['epochs'].astype('str')\n",
    "df.head()\n",
    "sns.lineplot(x='epoch', y='val_accuracy', hue='epochs', data=df);\n",
    "sns.lineplot(x='epoch', y='val_loss', hue='epochs', data=df);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd29c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
